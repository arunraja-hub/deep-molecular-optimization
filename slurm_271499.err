[I 2023-08-14 16:18:08,257] A new study created in memory with name: transformer-original-source2target-optuna-study
16:18:54: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:54: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:54: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:54: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:54: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:54: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:54: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:54: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:54: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:54: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:54: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:54: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:54: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:54: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:54: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:54: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:54: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:54: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:54: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:54: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:55: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:55: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:55: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:55: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:55: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:55: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:55: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:55: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:55: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:55: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:55: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:55: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:55: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:56: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:56: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:56: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:56: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:56: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:56: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:56: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:56: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:56: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:56: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:56: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:56: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:56: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:56: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:56: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:56: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:56: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:56: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:56: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:56: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:56: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:56: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:56: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:57: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py:59: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(p)
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.
  warnings.warn(warning.format(ret))
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:59: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +216: INFO     Training start
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:19:00: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:59: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:18:58: transformer_trainer.get_model +49: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:18:59: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:00: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:01: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:01: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start
16:19:02: transformer_trainer.train +216: INFO     Training start

  0%|          | 0/1257 [00:00<?, ?it/s][A



  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A





  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A






  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A


  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A







  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A  0%|          | 0/1257 [00:00<?, ?it/s]








  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A

  0%|          | 0/1257 [00:00<?, ?it/s][A[A




  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start










  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start
16:19:04: transformer_trainer.train +216: INFO     Training start











  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:05: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start












  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:05: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:06: transformer_trainer.train +214: INFO     Starting EPOCH #1













  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start














  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start















  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
16:19:06: transformer_trainer.train +216: INFO     Training start
















  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start
16:19:07: transformer_trainer.train +216: INFO     Training start

















  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start
16:19:08: transformer_trainer.train +216: INFO     Training start


















  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:08: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start



















  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start




















  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start





















  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start






















  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start























  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
























  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1

























  0%|          | 0/1257 [00:00<?, ?it/s]16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:09: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1


























16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start



























  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start




























  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start





























  0%|          | 0/1257 [00:00<?, ?it/s]16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start






























  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start































  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
































  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start

































16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
  0%|          | 0/1257 [00:00<?, ?it/s]16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:19:10: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start


































  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start



































16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start





































16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:10: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start




































  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start






































  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start







































  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start
16:19:11: transformer_trainer.train +216: INFO     Training start








































  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








































  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









































  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










































  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











































  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













































  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














































  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















































  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












































  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















































  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















































  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















































  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















































  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















































  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 1/1257 [00:12<4:20:16, 12.43s/it]








  0%|          | 1/1257 [00:12<4:26:50, 12.75s/it][A[A[A[A[A[A[A[A[A
  0%|          | 1/1257 [00:13<4:38:59, 13.33s/it][A



  0%|          | 1/1257 [00:13<4:34:54, 13.13s/it][A[A[A[A






  0%|          | 1/1257 [00:13<4:34:29, 13.11s/it][A[A[A[A[A[A[A









  0%|          | 1/1257 [00:11<4:07:39, 11.83s/it][A[A[A[A[A[A[A[A[A[A





  0%|          | 1/1257 [00:13<4:39:15, 13.34s/it][A[A[A[A[A[A










  0%|          | 1/1257 [00:09<3:20:16,  9.57s/it][A[A[A[A[A[A[A[A[A[A[A

















  0%|          | 1/1257 [00:07<2:40:33,  7.67s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




  0%|          | 1/1257 [00:13<4:35:18, 13.15s/it][A[A[A[A[A














  0%|          | 1/1257 [00:09<3:17:31,  9.44s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


  0%|          | 1/1257 [00:13<4:49:04, 13.81s/it][A[A[A





















  0%|          | 1/1257 [00:07<2:33:57,  7.35s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
























  0%|          | 1/1257 [00:06<2:10:39,  6.24s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1



















  0%|          | 1/1257 [00:08<2:47:49,  8.02s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















  0%|          | 1/1257 [00:09<3:24:16,  9.76s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:16: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start
16:19:17: transformer_trainer.train +216: INFO     Training start






















































  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















  0%|          | 1/1257 [00:09<3:20:47,  9.59s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















  0%|          | 1/1257 [00:08<3:00:15,  8.61s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












  0%|          | 1/1257 [00:10<3:48:08, 10.90s/it][A[A[A[A[A[A[A[A[A[A[A[A[A




















  0%|          | 1/1257 [00:08<3:02:46,  8.73s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +214: INFO     Starting EPOCH #1
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start
16:19:18: transformer_trainer.train +216: INFO     Training start























































  0%|          | 0/1257 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

  0%|          | 1/1257 [00:14<5:10:39, 14.84s/it][A[A







  0%|          | 1/1257 [00:15<5:22:54, 15.43s/it][A[A[A[A[A[A[A[A













  0%|          | 1/1257 [00:11<4:00:27, 11.49s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A




  0%|          | 2/1257 [00:15<3:26:07,  9.85s/it][A[A[A[A[A






















  0%|          | 1/1257 [00:08<2:54:16,  8.32s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








  0%|          | 2/1257 [00:15<3:26:57,  9.89s/it][A[A[A[A[A[A[A[A[A  0%|          | 2/1257 [00:16<3:24:46,  9.79s/it]











  0%|          | 1/1257 [00:12<4:20:22, 12.44s/it][A[A[A[A[A[A[A[A[A[A[A[A
  0%|          | 2/1257 [00:17<3:39:25, 10.49s/it][A






  0%|          | 2/1257 [00:17<3:36:53, 10.37s/it][A[A[A[A[A[A[A





























  0%|          | 1/1257 [00:08<2:57:08,  8.46s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






































  0%|          | 1/1257 [00:08<2:54:00,  8.31s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















































  0%|          | 1/1257 [00:08<2:49:13,  8.08s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





































  0%|          | 1/1257 [00:08<2:58:28,  8.53s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























  0%|          | 1/1257 [00:09<3:17:16,  9.42s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















  0%|          | 2/1257 [00:11<2:20:20,  6.71s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












































  0%|          | 1/1257 [00:08<2:56:00,  8.41s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























  0%|          | 1/1257 [00:09<3:20:18,  9.57s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















































  0%|          | 1/1257 [00:08<2:57:48,  8.49s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















































  0%|          | 1/1257 [00:08<2:58:22,  8.52s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




































  0%|          | 1/1257 [00:09<3:18:40,  9.49s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



































  0%|          | 1/1257 [00:09<3:22:22,  9.67s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















































  0%|          | 1/1257 [00:09<3:23:49,  9.74s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











































  0%|          | 1/1257 [00:09<3:27:28,  9.91s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












  0%|          | 2/1257 [00:15<3:07:05,  8.94s/it][A[A[A[A[A[A[A[A[A[A[A[A[A

























  0%|          | 1/1257 [00:11<3:50:52, 11.03s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





  0%|          | 2/1257 [00:19<3:53:11, 11.15s/it][A[A[A[A[A[A
















































  0%|          | 1/1257 [00:10<3:29:30, 10.01s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






























  0%|          | 1/1257 [00:10<3:42:58, 10.65s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














  0%|          | 2/1257 [00:15<2:54:59,  8.37s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










  0%|          | 2/1257 [00:15<2:58:52,  8.55s/it][A[A[A[A[A[A[A[A[A[A[A









































  0%|          | 1/1257 [00:10<3:40:56, 10.55s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









  0%|          | 2/1257 [00:18<3:34:48, 10.27s/it][A[A[A[A[A[A[A[A[A[A














































  0%|          | 1/1257 [00:10<3:37:51, 10.41s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A























  0%|          | 2/1257 [00:12<2:07:01,  6.07s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















































  0%|          | 1/1257 [00:10<3:35:06, 10.28s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


































  0%|          | 1/1257 [00:10<3:45:33, 10.78s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

































  0%|          | 1/1257 [00:11<3:46:29, 10.82s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



  0%|          | 2/1257 [00:20<3:55:21, 11.25s/it][A[A[A[A




  0%|          | 3/1257 [00:19<2:49:40,  8.12s/it][A[A[A[A[A





















  0%|          | 2/1257 [00:13<2:25:53,  6.97s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























  0%|          | 1/1257 [00:12<4:13:36, 12.11s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
































  0%|          | 1/1257 [00:11<4:09:46, 11.93s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








































  0%|          | 1/1257 [00:11<4:05:35, 11.73s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















  0%|          | 2/1257 [00:15<2:38:42,  7.59s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 3/1257 [00:20<2:53:47,  8.32s/it]
























  0%|          | 1/1257 [00:12<4:29:06, 12.86s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








  0%|          | 3/1257 [00:21<2:55:58,  8.42s/it][A[A[A[A[A[A[A[A[A

  0%|          | 2/1257 [00:21<4:14:56, 12.19s/it][A[A

















































  0%|          | 2/1257 [00:11<2:25:24,  6.95s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A







































  0%|          | 1/1257 [00:12<4:12:25, 12.06s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













  0%|          | 2/1257 [00:17<3:24:37,  9.78s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A















  0%|          | 2/1257 [00:17<3:11:32,  9.16s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










































  0%|          | 1/1257 [00:12<4:26:40, 12.74s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















  0%|          | 2/1257 [00:16<3:05:46,  8.88s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A































  0%|          | 1/1257 [00:13<4:33:44, 13.08s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


  0%|          | 2/1257 [00:21<4:13:19, 12.11s/it][A[A[A











  0%|          | 2/1257 [00:18<3:37:20, 10.39s/it][A[A[A[A[A[A[A[A[A[A[A[A






  0%|          | 3/1257 [00:21<3:02:24,  8.73s/it][A[A[A[A[A[A[A




















  0%|          | 2/1257 [00:16<2:53:38,  8.30s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















  0%|          | 2/1257 [00:14<2:41:20,  7.71s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















  0%|          | 2/1257 [00:16<2:54:40,  8.35s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























  0%|          | 2/1257 [00:14<2:50:16,  8.14s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















































  0%|          | 2/1257 [00:13<2:34:15,  7.38s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
  0%|          | 3/1257 [00:23<3:10:26,  9.11s/it][A























  0%|          | 3/1257 [00:15<1:50:03,  5.27s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






































  0%|          | 2/1257 [00:14<2:38:01,  7.55s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





































  0%|          | 2/1257 [00:14<2:39:51,  7.64s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















  0%|          | 3/1257 [00:17<2:12:43,  6.35s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A







  0%|          | 2/1257 [00:23<4:35:08, 13.15s/it][A[A[A[A[A[A[A[A













































  0%|          | 1/1257 [00:14<4:53:43, 14.03s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




  0%|          | 4/1257 [00:22<2:20:54,  6.75s/it][A[A[A[A[A



  0%|          | 3/1257 [00:23<3:08:24,  9.01s/it][A[A[A[A





























  0%|          | 2/1257 [00:15<2:48:00,  8.03s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









  0%|          | 3/1257 [00:23<3:00:20,  8.63s/it][A[A[A[A[A[A[A[A[A[A








  0%|          | 4/1257 [00:24<2:28:10,  7.10s/it][A[A[A[A[A[A[A[A[A  0%|          | 4/1257 [00:25<2:27:28,  7.06s/it]














  0%|          | 3/1257 [00:21<2:38:51,  7.60s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















  0%|          | 3/1257 [00:19<2:18:09,  6.61s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










  0%|          | 3/1257 [00:22<2:45:21,  7.91s/it][A[A[A[A[A[A[A[A[A[A[A





  0%|          | 3/1257 [00:26<3:25:24,  9.83s/it][A[A[A[A[A[A

  0%|          | 3/1257 [00:26<3:31:41, 10.13s/it][A[A






  0%|          | 4/1257 [00:26<2:36:24,  7.49s/it][A[A[A[A[A[A[A























  0%|          | 4/1257 [00:18<1:38:40,  4.72s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















  0%|          | 4/1257 [00:20<1:55:29,  5.53s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















































  0%|          | 1/1257 [00:12<4:24:13, 12.62s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A







  0%|          | 3/1257 [00:27<3:36:38, 10.37s/it][A[A[A[A[A[A[A[A























  0%|          | 5/1257 [00:19<1:13:27,  3.52s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






  0%|          | 5/1257 [00:27<1:54:41,  5.50s/it][A[A[A[A[A[A[A



  0%|          | 4/1257 [00:27<2:35:38,  7.45s/it][A[A[A[A










  0%|          | 4/1257 [00:23<2:04:50,  5.98s/it][A[A[A[A[A[A[A[A[A[A[A





  0%|          | 4/1257 [00:27<2:32:30,  7.30s/it][A[A[A[A[A[A














  0%|          | 4/1257 [00:23<2:04:16,  5.95s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















  0%|          | 4/1257 [00:21<1:49:23,  5.24s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









  0%|          | 4/1257 [00:26<2:26:44,  7.03s/it][A[A[A[A[A[A[A[A[A[A
  0%|          | 4/1257 [00:28<2:45:55,  7.95s/it][A


















  0%|          | 5/1257 [00:21<1:28:10,  4.23s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

  0%|          | 4/1257 [00:27<2:38:14,  7.58s/it][A[A





















































  0%|          | 2/1257 [00:14<3:14:38,  9.31s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A







  0%|          | 4/1257 [00:28<2:41:26,  7.73s/it][A[A[A[A[A[A[A[A






  0%|          | 6/1257 [00:28<1:29:34,  4.30s/it][A[A[A[A[A[A[A


















  0%|          | 6/1257 [00:22<1:07:46,  3.25s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A























  0%|          | 6/1257 [00:21<1:02:48,  3.01s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















































  0%|          | 3/1257 [00:15<2:21:56,  6.79s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A







  0%|          | 5/1257 [00:29<1:58:23,  5.67s/it][A[A[A[A[A[A[A[A





















































  0%|          | 4/1257 [00:15<1:42:58,  4.93s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






  1%|          | 7/1257 [00:30<1:10:06,  3.37s/it][A[A[A[A[A[A[A























  1%|          | 7/1257 [00:22<50:15,  2.41s/it]  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















  1%|          | 7/1257 [00:24<54:39,  2.62s/it]  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








  0%|          | 5/1257 [00:30<2:19:03,  6.66s/it][A[A[A[A[A[A[A[A[A












  0%|          | 3/1257 [00:27<3:24:22,  9.78s/it][A[A[A[A[A[A[A[A[A[A[A[A[A





































  0%|          | 3/1257 [00:22<2:42:20,  7.77s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 5/1257 [00:31<2:20:57,  6.76s/it]




  0%|          | 5/1257 [00:30<2:27:50,  7.08s/it][A[A[A[A[A









  0%|          | 5/1257 [00:30<2:04:34,  5.97s/it][A[A[A[A[A[A[A[A[A[A





















  0%|          | 5/1257 [00:25<1:41:35,  4.87s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















  0%|          | 3/1257 [00:24<2:53:11,  8.29s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



  0%|          | 5/1257 [00:32<2:18:06,  6.62s/it][A[A[A[A







  0%|          | 6/1257 [00:32<1:38:59,  4.75s/it][A[A[A[A[A[A[A[A




















  0%|          | 3/1257 [00:26<3:03:59,  8.80s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








  0%|          | 6/1257 [00:32<1:47:04,  5.14s/it][A[A[A[A[A[A[A[A[A



































  0%|          | 2/1257 [00:23<3:47:02, 10.85s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


  0%|          | 3/1257 [00:32<4:05:09, 11.73s/it][A[A[A






































  0%|          | 3/1257 [00:23<2:51:15,  8.19s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















































  0%|          | 2/1257 [00:23<3:49:46, 10.99s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











  0%|          | 3/1257 [00:29<3:41:38, 10.60s/it][A[A[A[A[A[A[A[A[A[A[A[A


























  0%|          | 3/1257 [00:24<3:04:53,  8.85s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














  0%|          | 5/1257 [00:28<2:02:27,  5.87s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















































  0%|          | 2/1257 [00:23<3:53:20, 11.16s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

  0%|          | 5/1257 [00:32<2:22:50,  6.85s/it][A[A





























  0%|          | 3/1257 [00:24<2:54:10,  8.33s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















  0%|          | 3/1257 [00:27<3:09:11,  9.05s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















































  0%|          | 2/1257 [00:23<3:37:41, 10.41s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













  0%|          | 3/1257 [00:29<3:38:31, 10.46s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A
  0%|          | 5/1257 [00:33<2:29:39,  7.17s/it][A



















































  0%|          | 3/1257 [00:23<2:54:40,  8.36s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










  0%|          | 5/1257 [00:29<2:03:58,  5.94s/it][A[A[A[A[A[A[A[A[A[A[A





  0%|          | 5/1257 [00:33<2:23:21,  6.87s/it][A[A[A[A[A[A
































  0%|          | 2/1257 [00:24<4:13:31, 12.12s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








































  0%|          | 2/1257 [00:24<4:10:20, 11.97s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























  0%|          | 2/1257 [00:25<3:57:02, 11.33s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















































  0%|          | 2/1257 [00:24<3:57:00, 11.33s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A







































  0%|          | 2/1257 [00:24<4:14:32, 12.17s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

























  0%|          | 2/1257 [00:25<4:11:31, 12.02s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A































  0%|          | 2/1257 [00:24<4:25:09, 12.68s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
























  0%|          | 2/1257 [00:25<4:27:38, 12.80s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






  1%|          | 8/1257 [00:33<1:12:01,  3.46s/it][A[A[A[A[A[A[A













































  0%|          | 2/1257 [00:24<4:31:03, 12.96s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















  1%|          | 8/1257 [00:27<1:00:56,  2.93s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




































  0%|          | 2/1257 [00:24<3:54:51, 11.23s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












  0%|          | 4/1257 [00:30<2:44:40,  7.89s/it][A[A[A[A[A[A[A[A[A[A[A[A[A

































  0%|          | 2/1257 [00:25<4:10:27, 11.97s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












































  0%|          | 2/1257 [00:25<3:47:49, 10.89s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




  0%|          | 6/1257 [00:34<2:03:03,  5.90s/it][A[A[A[A[A
















  0%|          | 3/1257 [00:29<3:28:47,  9.99s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






























  0%|          | 2/1257 [00:25<4:10:45, 11.99s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















  0%|          | 3/1257 [00:28<3:17:06,  9.43s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















































  0%|          | 3/1257 [00:25<3:07:34,  8.98s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























  0%|          | 2/1257 [00:26<4:25:57, 12.72s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














































  0%|          | 2/1257 [00:25<4:08:08, 11.86s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















  0%|          | 3/1257 [00:30<3:36:36, 10.36s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










































  0%|          | 2/1257 [00:26<4:30:07, 12.91s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


































  0%|          | 2/1257 [00:26<4:14:42, 12.18s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









































  0%|          | 2/1257 [00:26<4:11:58, 12.05s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 6/1257 [00:35<2:03:24,  5.92s/it]











































  0%|          | 2/1257 [00:25<4:06:03, 11.76s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





































  0%|          | 4/1257 [00:26<2:23:33,  6.87s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








  1%|          | 7/1257 [00:36<1:39:04,  4.76s/it][A[A[A[A[A[A[A[A[A























  1%|          | 8/1257 [00:28<1:13:14,  3.52s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



  0%|          | 6/1257 [00:36<2:05:20,  6.01s/it][A[A[A[A




















  0%|          | 4/1257 [00:31<2:42:27,  7.78s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















  0%|          | 4/1257 [00:30<2:37:25,  7.54s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















































  0%|          | 5/1257 [00:24<2:04:52,  5.98s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[W 2023-08-14 16:19:41,335] Trial 26 failed with parameters: {'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 75.87 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 21, in forward
    x = layer(x, memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 22, in forward
    x = self.sublayer[0](x, lambda x: self.self_attn(
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/layer_norm.py", line 17, in forward
    return self.a_2 * (x - mean) / (std + self.eps) + self.b_2
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 75.87 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:41,339] Trial 55 failed with parameters: {'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 75.87 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder.py", line 19, in forward
    x = layer(x, mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in forward
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in <lambda>
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 16, in attention
    scores = scores.masked_fill(mask == 0, -1e9)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 75.87 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:41,851] Trial 55 failed with value None.
[W 2023-08-14 16:19:41,359] Trial 51 failed with parameters: {'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 79.15 GiB total capacity; 75.85 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 21, in forward
    x = layer(x, memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 22, in forward
    x = self.sublayer[0](x, lambda x: self.self_attn(
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 23, in <lambda>
    x, x, x, tgt_mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 16, in attention
    scores = scores.masked_fill(mask == 0, -1e9)
RuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 79.15 GiB total capacity; 75.85 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:41,363] Trial 24 failed with parameters: {'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 75.85 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 106, in train_epoch
    loss = loss_compute(out, trg_y, ntokens)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/simpleloss_compute.py", line 18, in __call__
    loss.backward()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 75.85 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:41,408] Trial 33 failed with parameters: {'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 46.00 MiB (GPU 0; 79.15 GiB total capacity; 75.70 GiB already allocated; 25.25 MiB free; 78.30 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 21, in forward
    x = layer(x, memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 24, in forward
    x = self.sublayer[1](x, lambda x: self.src_attn(
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 25, in <lambda>
    x, m, m, src_mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 13, in attention
    scores = torch.matmul(query, key.transpose(-2, -1)) \
RuntimeError: CUDA out of memory. Tried to allocate 46.00 MiB (GPU 0; 79.15 GiB total capacity; 75.70 GiB already allocated; 25.25 MiB free; 78.30 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:41,431] Trial 10 failed with parameters: {'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 75.69 GiB already allocated; 5.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 23, in forward
    return self.norm(x)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/layer_norm.py", line 17, in forward
    return self.a_2 * (x - mean) / (std + self.eps) + self.b_2
RuntimeError: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 75.69 GiB already allocated; 5.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:41,639] Trial 20 failed with parameters: {'N': 2, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 75.83 GiB already allocated; 5.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 21, in forward
    x = layer(x, memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 27, in forward
    return self.sublayer[2](x, self.feed_forward)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/positionwise_feedforward.py", line 15, in forward
    return self.w_2(self.dropout(F.relu(self.w_1(x))))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/dropout.py", line 54, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 807, in dropout
    else _VF.dropout(input, p, training))
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 75.83 GiB already allocated; 5.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:42,030] Trial 20 failed with value None.
[W 2023-08-14 16:19:41,653] Trial 37 failed with parameters: {'N': 4, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 75.83 GiB already allocated; 5.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder.py", line 19, in forward
    x = layer(x, mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 20, in forward
    return self.sublayer[1](x, self.feed_forward)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/positionwise_feedforward.py", line 15, in forward
    return self.w_2(self.dropout(F.relu(self.w_1(x))))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 914, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 75.83 GiB already allocated; 5.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:42,034] Trial 37 failed with value None.
[W 2023-08-14 16:19:41,677] Trial 53 failed with parameters: {'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 75.83 GiB already allocated; 5.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 106, in train_epoch
    loss = loss_compute(out, trg_y, ntokens)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/simpleloss_compute.py", line 18, in __call__
    loss.backward()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 75.83 GiB already allocated; 5.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:41,699] Trial 25 failed with parameters: {'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 75.83 GiB already allocated; 5.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 21, in forward
    x = layer(x, memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 24, in forward
    x = self.sublayer[1](x, lambda x: self.src_attn(
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 25, in <lambda>
    x, m, m, src_mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 45, in forward
    for l, x in zip(self.linears, (query, key, value))]
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 45, in <listcomp>
    for l, x in zip(self.linears, (query, key, value))]
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 1372, in linear
    output = input.matmul(weight.t())
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 75.83 GiB already allocated; 5.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:42,060] Trial 25 failed with value None.
[W 2023-08-14 16:19:41,732] Trial 40 failed with parameters: {'N': 8, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 75.71 GiB already allocated; 5.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 106, in train_epoch
    loss = loss_compute(out, trg_y, ntokens)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/simpleloss_compute.py", line 18, in __call__
    loss.backward()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 75.71 GiB already allocated; 5.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:41,742] Trial 49 failed with parameters: {'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 75.83 GiB already allocated; 5.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder.py", line 19, in forward
    x = layer(x, mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in forward
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in <lambda>
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 13, in attention
    scores = torch.matmul(query, key.transpose(-2, -1)) \
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 75.83 GiB already allocated; 5.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:42,088] Trial 49 failed with value None.
[W 2023-08-14 16:19:41,743] Trial 12 failed with parameters: {'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 75.82 GiB already allocated; 5.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 106, in train_epoch
    loss = loss_compute(out, trg_y, ntokens)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/simpleloss_compute.py", line 18, in __call__
    loss.backward()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 75.82 GiB already allocated; 5.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:42,091] Trial 12 failed with value None.
[W 2023-08-14 16:19:41,812] Trial 26 failed with value None.
[W 2023-08-14 16:19:41,353] Trial 3 failed with parameters: {'N': 2, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 46.00 MiB (GPU 0; 79.15 GiB total capacity; 75.85 GiB already allocated; 23.25 MiB free; 78.30 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 106, in train_epoch
    loss = loss_compute(out, trg_y, ntokens)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/simpleloss_compute.py", line 18, in __call__
    loss.backward()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 46.00 MiB (GPU 0; 79.15 GiB total capacity; 75.85 GiB already allocated; 23.25 MiB free; 78.30 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:42,099] Trial 3 failed with value None.
[W 2023-08-14 16:19:41,961] Trial 24 failed with value None.
[W 2023-08-14 16:19:41,967] Trial 33 failed with value None.










  0%|          | 6/1257 [00:37<2:15:57,  6.52s/it][A[A[A[A[A[A[A[A[A[A[W 2023-08-14 16:19:41,971] Trial 10 failed with value None.
[W 2023-08-14 16:19:41,653] Trial 0 failed with parameters: {'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 75.83 GiB already allocated; 5.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 106, in train_epoch
    loss = loss_compute(out, trg_y, ntokens)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/simpleloss_compute.py", line 18, in __call__
    loss.backward()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 75.83 GiB already allocated; 5.25 MiB free; 78.32 GiB reserved in total by PyTorch)



























  0%|          | 4/1257 [00:30<2:47:03,  8.00s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[W 2023-08-14 16:19:41,678] Trial 9 failed with parameters: {'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 75.83 GiB already allocated; 5.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 21, in forward
    x = layer(x, memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 24, in forward
    x = self.sublayer[1](x, lambda x: self.src_attn(
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 25, in <lambda>
    x, m, m, src_mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 13, in attention
    scores = torch.matmul(query, key.transpose(-2, -1)) \
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 75.83 GiB already allocated; 5.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:42,043] Trial 53 failed with value None.
[W 2023-08-14 16:19:41,707] Trial 29 failed with parameters: {'N': 2, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 75.83 GiB already allocated; 5.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 21, in forward
    x = layer(x, memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 22, in forward
    x = self.sublayer[0](x, lambda x: self.self_attn(
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 23, in <lambda>
    x, x, x, tgt_mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 45, in forward
    for l, x in zip(self.linears, (query, key, value))]
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 45, in <listcomp>
    for l, x in zip(self.linears, (query, key, value))]
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 1372, in linear
    output = input.matmul(weight.t())
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 75.83 GiB already allocated; 5.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:42,128] Trial 29 failed with value None.
[W 2023-08-14 16:19:42,080] Trial 40 failed with value None.
[W 2023-08-14 16:19:41,753] Trial 39 failed with parameters: {'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 40.00 MiB (GPU 0; 79.15 GiB total capacity; 75.51 GiB already allocated; 29.25 MiB free; 78.30 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 106, in train_epoch
    loss = loss_compute(out, trg_y, ntokens)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/simpleloss_compute.py", line 18, in __call__
    loss.backward()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 40.00 MiB (GPU 0; 79.15 GiB total capacity; 75.51 GiB already allocated; 29.25 MiB free; 78.30 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:42,129] Trial 39 failed with value None.
[W 2023-08-14 16:19:41,942] Trial 51 failed with value None.
[W 2023-08-14 16:19:42,127] Trial 9 failed with value None.
[W 2023-08-14 16:19:41,750] Trial 23 failed with parameters: {'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 79.15 GiB total capacity; 75.76 GiB already allocated; 5.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 106, in train_epoch
    loss = loss_compute(out, trg_y, ntokens)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/simpleloss_compute.py", line 18, in __call__
    loss.backward()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 79.15 GiB total capacity; 75.76 GiB already allocated; 5.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:42,131] Trial 23 failed with value None.
[W 2023-08-14 16:19:42,116] Trial 0 failed with value None.




















































  0%|          | 4/1257 [00:30<2:41:02,  7.71s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










  0%|          | 6/1257 [00:35<2:05:30,  6.02s/it][A[A[A[A[A[A[A[A[A[A[A



































  0%|          | 3/1257 [00:30<3:25:15,  9.82s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















  0%|          | 6/1257 [00:33<2:01:56,  5.85s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






































  0%|          | 4/1257 [00:30<2:43:24,  7.82s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

  0%|          | 6/1257 [00:39<2:21:42,  6.80s/it][A[A
















  0%|          | 4/1257 [00:34<3:00:28,  8.64s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





































  0%|          | 5/1257 [00:30<2:04:57,  5.99s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















  1%|          | 9/1257 [00:33<1:20:55,  3.89s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














  0%|          | 6/1257 [00:35<2:08:20,  6.16s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











  0%|          | 4/1257 [00:36<3:18:32,  9.51s/it][A[A[A[A[A[A[A[A[A[A[A[A





  0%|          | 6/1257 [00:40<2:22:03,  6.81s/it][A[A[A[A[A[A

















  0%|          | 4/1257 [00:34<2:52:40,  8.27s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













  0%|          | 4/1257 [00:36<3:17:57,  9.48s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A







  1%|          | 7/1257 [00:40<2:02:17,  5.87s/it][A[A[A[A[A[A[A[A




















  0%|          | 5/1257 [00:34<2:13:09,  6.38s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



  1%|          | 7/1257 [00:40<1:53:24,  5.44s/it][A[A[A[A[W 2023-08-14 16:19:44,261] Trial 14 failed with parameters: {'N': 2, 'd_model': 512, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 79.15 GiB total capacity; 73.38 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 106, in train_epoch
    loss = loss_compute(out, trg_y, ntokens)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/simpleloss_compute.py", line 18, in __call__
    loss.backward()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 79.15 GiB total capacity; 73.38 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:44,262] Trial 47 failed with parameters: {'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 40.00 MiB (GPU 0; 79.15 GiB total capacity; 73.44 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 21, in forward
    x = layer(x, memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 24, in forward
    x = self.sublayer[1](x, lambda x: self.src_attn(
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 25, in <lambda>
    x, m, m, src_mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 14, in attention
    / math.sqrt(d_k)
RuntimeError: CUDA out of memory. Tried to allocate 40.00 MiB (GPU 0; 79.15 GiB total capacity; 73.44 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:44,283] Trial 5 failed with parameters: {'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 8, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 73.43 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 21, in forward
    x = layer(x, memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 24, in forward
    x = self.sublayer[1](x, lambda x: self.src_attn(
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 25, in <lambda>
    x, m, m, src_mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 16, in attention
    scores = scores.masked_fill(mask == 0, -1e9)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 73.43 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:44,294] Trial 5 failed with value None.
[W 2023-08-14 16:19:44,288] Trial 47 failed with value None.
[W 2023-08-14 16:19:44,288] Trial 14 failed with value None.
[W 2023-08-14 16:19:44,343] Trial 34 failed with parameters: {'N': 6, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 79.15 GiB total capacity; 73.41 GiB already allocated; 9.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 106, in train_epoch
    loss = loss_compute(out, trg_y, ntokens)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/simpleloss_compute.py", line 18, in __call__
    loss.backward()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 79.15 GiB total capacity; 73.41 GiB already allocated; 9.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:44,355] Trial 34 failed with value None.























































  0%|          | 1/1257 [00:26<9:11:06, 26.33s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[W 2023-08-14 16:19:44,358] Trial 6 failed with parameters: {'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 73.41 GiB already allocated; 9.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder.py", line 19, in forward
    x = layer(x, mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 20, in forward
    return self.sublayer[1](x, self.feed_forward)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/dropout.py", line 54, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 807, in dropout
    else _VF.dropout(input, p, training))
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 73.41 GiB already allocated; 9.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:44,396] Trial 6 failed with value None.
[W 2023-08-14 16:19:44,359] Trial 17 failed with parameters: {'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 79.15 GiB total capacity; 73.41 GiB already allocated; 9.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder.py", line 19, in forward
    x = layer(x, mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in forward
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in <lambda>
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 13, in attention
    scores = torch.matmul(query, key.transpose(-2, -1)) \
RuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 79.15 GiB total capacity; 73.41 GiB already allocated; 9.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:44,403] Trial 17 failed with value None.
[W 2023-08-14 16:19:44,404] Trial 19 failed with parameters: {'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 8, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 42.00 MiB (GPU 0; 79.15 GiB total capacity; 73.38 GiB already allocated; 29.25 MiB free; 78.30 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder.py", line 19, in forward
    x = layer(x, mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in forward
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in <lambda>
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 13, in attention
    scores = torch.matmul(query, key.transpose(-2, -1)) \
RuntimeError: CUDA out of memory. Tried to allocate 42.00 MiB (GPU 0; 79.15 GiB total capacity; 73.38 GiB already allocated; 29.25 MiB free; 78.30 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:44,404] Trial 19 failed with value None.
[W 2023-08-14 16:19:44,550] Trial 27 failed with parameters: {'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 38.00 MiB (GPU 0; 79.15 GiB total capacity; 73.68 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder.py", line 19, in forward
    x = layer(x, mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in forward
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in <lambda>
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 19, in attention
    p_attn = dropout(p_attn)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/dropout.py", line 54, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 807, in dropout
    else _VF.dropout(input, p, training))
RuntimeError: CUDA out of memory. Tried to allocate 38.00 MiB (GPU 0; 79.15 GiB total capacity; 73.68 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:44,602] Trial 43 failed with parameters: {'N': 8, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 40.00 MiB (GPU 0; 79.15 GiB total capacity; 73.38 GiB already allocated; 31.25 MiB free; 78.29 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 106, in train_epoch
    loss = loss_compute(out, trg_y, ntokens)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/simpleloss_compute.py", line 18, in __call__
    loss.backward()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 40.00 MiB (GPU 0; 79.15 GiB total capacity; 73.38 GiB already allocated; 31.25 MiB free; 78.29 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:44,605] Trial 43 failed with value None.
[W 2023-08-14 16:19:44,605] Trial 27 failed with value None.










  1%|          | 7/1257 [00:40<1:51:33,  5.35s/it][A[A[A[A[A[A[A[A[A[A










  1%|          | 7/1257 [00:38<1:42:12,  4.91s/it][A[A[A[A[A[A[A[A[A[A[A














  1%|          | 7/1257 [00:37<1:42:07,  4.90s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



































  0%|          | 4/1257 [00:33<2:39:05,  7.62s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















  1%|          | 7/1257 [00:35<1:40:41,  4.83s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





































  0%|          | 6/1257 [00:33<1:42:23,  4.91s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















































  0%|          | 5/1257 [00:33<2:11:39,  6.31s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















  0%|          | 6/1257 [00:36<1:44:21,  5.01s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























  0%|          | 5/1257 [00:34<2:18:23,  6.63s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






































  0%|          | 5/1257 [00:33<2:11:37,  6.31s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















  0%|          | 5/1257 [00:37<2:23:30,  6.88s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










  1%|          | 8/1257 [00:39<1:17:59,  3.75s/it][A[A[A[A[A[A[A[A[A[A[A














  1%|          | 8/1257 [00:38<1:17:15,  3.71s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









  1%|          | 8/1257 [00:41<1:25:14,  4.09s/it][A[A[A[A[A[A[A[A[A[A





















  1%|          | 8/1257 [00:36<1:17:11,  3.71s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





































  1%|          | 7/1257 [00:34<1:18:25,  3.76s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



































  0%|          | 5/1257 [00:34<1:59:06,  5.71s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















  1%|          | 7/1257 [00:37<1:19:37,  3.82s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










  1%|          | 9/1257 [00:40<1:00:46,  2.92s/it][A[A[A[A[A[A[A[A[A[A[A





















  1%|          | 9/1257 [00:37<58:24,  2.81s/it]  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














  1%|          | 9/1257 [00:39<1:02:04,  2.98s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









  1%|          | 9/1257 [00:42<1:07:32,  3.25s/it][A[A[A[A[A[A[A[A[A[A




















  1%|          | 8/1257 [00:38<59:55,  2.88s/it]  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





































  1%|          | 8/1257 [00:35<1:02:08,  2.99s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



































  0%|          | 6/1257 [00:35<1:30:21,  4.33s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






































  0%|          | 6/1257 [00:35<1:44:54,  5.03s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























  0%|          | 6/1257 [00:36<1:49:47,  5.27s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















  1%|          | 10/1257 [00:38<45:28,  2.19s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















































  0%|          | 6/1257 [00:35<1:47:08,  5.14s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















  0%|          | 6/1257 [00:39<1:54:47,  5.51s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










  1%|          | 10/1257 [00:41<51:10,  2.46s/it] [A[A[A[A[A[A[A[A[A[A[A















































  0%|          | 3/1257 [00:36<3:47:46, 10.90s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























  0%|          | 3/1257 [00:37<4:01:24, 11.55s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









































  0%|          | 3/1257 [00:36<4:01:00, 11.53s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A































  0%|          | 3/1257 [00:36<4:20:09, 12.45s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














  1%|          | 10/1257 [00:41<52:13,  2.51s/it] [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














































  0%|          | 3/1257 [00:36<4:00:20, 11.50s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

























  0%|          | 3/1257 [00:37<4:12:28, 12.08s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















































  0%|          | 3/1257 [00:36<4:00:59, 11.53s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























  0%|          | 3/1257 [00:37<4:14:48, 12.19s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
































  0%|          | 3/1257 [00:37<4:16:11, 12.26s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










































  0%|          | 3/1257 [00:36<4:17:02, 12.30s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A







































  0%|          | 3/1257 [00:37<4:17:47, 12.33s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








































  0%|          | 3/1257 [00:37<4:16:32, 12.28s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











































  0%|          | 3/1257 [00:37<4:01:43, 11.57s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
























  0%|          | 3/1257 [00:38<4:29:12, 12.88s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















































  0%|          | 3/1257 [00:37<4:10:33, 11.99s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















































  0%|          | 2/1257 [00:32<7:01:08, 20.13s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









  1%|          | 10/1257 [00:45<1:05:23,  3.15s/it][A[A[A[A[A[A[A[A[A[A













































  0%|          | 3/1257 [00:38<4:34:21, 13.13s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















  1%|          | 9/1257 [00:41<1:00:33,  2.91s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



































  1%|          | 7/1257 [00:38<1:21:22,  3.91s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















  1%|          | 7/1257 [00:42<1:37:53,  4.70s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





































  1%|          | 9/1257 [00:39<1:06:20,  3.19s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










  1%|          | 11/1257 [00:44<55:43,  2.68s/it][A[A[A[A[A[A[A[A[A[A[A[W 2023-08-14 16:19:51,593] Trial 32 failed with parameters: {'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 73.94 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder.py", line 19, in forward
    x = layer(x, mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in forward
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in <lambda>
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 20, in attention
    return torch.matmul(p_attn, value), p_attn
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 73.94 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:51,640] Trial 13 failed with parameters: {'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 79.15 GiB total capacity; 73.87 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 106, in train_epoch
    loss = loss_compute(out, trg_y, ntokens)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/simpleloss_compute.py", line 18, in __call__
    loss.backward()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 79.15 GiB total capacity; 73.87 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:51,659] Trial 30 failed with parameters: {'N': 10, 'd_model': 256, 'd_ff': 1024, 'h': 8, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 73.86 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 106, in train_epoch
    loss = loss_compute(out, trg_y, ntokens)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/simpleloss_compute.py", line 18, in __call__
    loss.backward()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 73.86 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:51,773] Trial 30 failed with value None.
[W 2023-08-14 16:19:51,660] Trial 32 failed with value None.
[W 2023-08-14 16:19:51,792] Trial 21 failed with parameters: {'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 79.15 GiB total capacity; 73.64 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 106, in train_epoch
    loss = loss_compute(out, trg_y, ntokens)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/simpleloss_compute.py", line 18, in __call__
    loss.backward()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 79.15 GiB total capacity; 73.64 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:51,770] Trial 2 failed with parameters: {'N': 10, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 73.90 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 21, in forward
    x = layer(x, memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 22, in forward
    x = self.sublayer[0](x, lambda x: self.self_attn(
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 23, in <lambda>
    x, x, x, tgt_mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 45, in forward
    for l, x in zip(self.linears, (query, key, value))]
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 45, in <listcomp>
    for l, x in zip(self.linears, (query, key, value))]
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 1372, in linear
    output = input.matmul(weight.t())
RuntimeError: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 73.90 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:51,773] Trial 22 failed with parameters: {'N': 10, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 73.62 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 106, in train_epoch
    loss = loss_compute(out, trg_y, ntokens)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/simpleloss_compute.py", line 18, in __call__
    loss.backward()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 73.62 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)






















  1%|          | 11/1257 [00:42<57:01,  2.75s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[W 2023-08-14 16:19:51,660] Trial 46 failed with parameters: {'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 73.86 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 21, in forward
    x = layer(x, memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 24, in forward
    x = self.sublayer[1](x, lambda x: self.src_attn(
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 25, in <lambda>
    x, m, m, src_mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 45, in forward
    for l, x in zip(self.linears, (query, key, value))]
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 45, in <listcomp>
    for l, x in zip(self.linears, (query, key, value))]
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 1372, in linear
    output = input.matmul(weight.t())
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 73.86 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)















[W 2023-08-14 16:19:51,792] Trial 21 failed with value None.
  1%|          | 11/1257 [00:44<57:08,  2.75s/it][W 2023-08-14 16:19:51,741] Trial 13 failed with value None.
[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[W 2023-08-14 16:19:51,792] Trial 8 failed with parameters: {'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 73.86 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 106, in train_epoch
    loss = loss_compute(out, trg_y, ntokens)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/simpleloss_compute.py", line 18, in __call__
    loss.backward()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 73.86 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)



























  1%|          | 7/1257 [00:40<1:43:25,  4.96s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[W 2023-08-14 16:19:51,796] Trial 31 failed with parameters: {'N': 6, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 79.15 GiB total capacity; 73.62 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder.py", line 19, in forward
    x = layer(x, mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in forward
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in <lambda>
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 16, in attention
    scores = scores.masked_fill(mask == 0, -1e9)
RuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 79.15 GiB total capacity; 73.62 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:51,904] Trial 31 failed with value None.
[W 2023-08-14 16:19:51,805] Trial 2 failed with value None.
[W 2023-08-14 16:19:51,842] Trial 22 failed with value None.







































  1%|          | 7/1257 [00:39<1:40:12,  4.81s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[W 2023-08-14 16:19:51,845] Trial 52 failed with parameters: {'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 79.15 GiB total capacity; 73.33 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 21, in forward
    x = layer(x, memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 24, in forward
    x = self.sublayer[1](x, lambda x: self.src_attn(
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 25, in <lambda>
    x, m, m, src_mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 19, in attention
    p_attn = dropout(p_attn)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/dropout.py", line 54, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 807, in dropout
    else _VF.dropout(input, p, training))
RuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 79.15 GiB total capacity; 73.33 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:51,921] Trial 52 failed with value None.
[W 2023-08-14 16:19:51,874] Trial 7 failed with parameters: {'N': 8, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 79.15 GiB total capacity; 73.50 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 21, in forward
    x = layer(x, memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 24, in forward
    x = self.sublayer[1](x, lambda x: self.src_attn(
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 25, in <lambda>
    x, m, m, src_mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 19, in attention
    p_attn = dropout(p_attn)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/dropout.py", line 54, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 807, in dropout
    else _VF.dropout(input, p, training))
RuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 79.15 GiB total capacity; 73.50 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:51,876] Trial 45 failed with parameters: {'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 79.15 GiB total capacity; 73.25 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 106, in train_epoch
    loss = loss_compute(out, trg_y, ntokens)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/simpleloss_compute.py", line 18, in __call__
    loss.backward()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 79.15 GiB total capacity; 73.25 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:51,948] Trial 45 failed with value None.
[W 2023-08-14 16:19:51,901] Trial 8 failed with value None.
[W 2023-08-14 16:19:51,872] Trial 46 failed with value None.
[W 2023-08-14 16:19:51,928] Trial 7 failed with value None.
[W 2023-08-14 16:19:51,807] Trial 15 failed with parameters: {'N': 4, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 79.15 GiB total capacity; 73.61 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder.py", line 19, in forward
    x = layer(x, mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in forward
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in <lambda>
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 14, in attention
    / math.sqrt(d_k)
RuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 79.15 GiB total capacity; 73.61 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:51,965] Trial 15 failed with value None.




























  0%|          | 4/1257 [00:40<3:11:10,  9.15s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















































  1%|          | 7/1257 [00:39<1:41:32,  4.87s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









































  0%|          | 4/1257 [00:40<3:11:47,  9.18s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














































  0%|          | 4/1257 [00:39<3:10:36,  9.13s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
































  0%|          | 4/1257 [00:40<3:20:13,  9.59s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















































  0%|          | 4/1257 [00:40<3:10:52,  9.14s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















































  0%|          | 4/1257 [00:40<3:05:00,  8.86s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























  0%|          | 4/1257 [00:41<3:22:21,  9.69s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















































  0%|          | 4/1257 [00:40<3:12:34,  9.22s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

























  0%|          | 4/1257 [00:41<3:22:12,  9.68s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[W 2023-08-14 16:19:53,219] Trial 41 failed with parameters: {'N': 6, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 74.76 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder.py", line 19, in forward
    x = layer(x, mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in forward
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in <lambda>
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 13, in attention
    scores = torch.matmul(query, key.transpose(-2, -1)) \
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 74.76 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:53,299] Trial 41 failed with value None.
[W 2023-08-14 16:19:53,222] Trial 50 failed with parameters: {'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 74.67 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder.py", line 19, in forward
    x = layer(x, mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in forward
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in <lambda>
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 13, in attention
    scores = torch.matmul(query, key.transpose(-2, -1)) \
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 74.67 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:53,299] Trial 50 failed with value None.
[W 2023-08-14 16:19:53,270] Trial 28 failed with parameters: {'N': 10, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 74.75 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 106, in train_epoch
    loss = loss_compute(out, trg_y, ntokens)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/simpleloss_compute.py", line 18, in __call__
    loss.backward()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 74.75 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:53,302] Trial 28 failed with value None.
[W 2023-08-14 16:19:53,259] Trial 4 failed with parameters: {'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 74.83 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder.py", line 19, in forward
    x = layer(x, mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in forward
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in <lambda>
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 13, in attention
    scores = torch.matmul(query, key.transpose(-2, -1)) \
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 74.83 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:53,309] Trial 4 failed with value None.
[W 2023-08-14 16:19:53,308] Trial 36 failed with parameters: {'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 74.76 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder.py", line 19, in forward
    x = layer(x, mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in forward
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in <lambda>
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 13, in attention
    scores = torch.matmul(query, key.transpose(-2, -1)) \
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 74.76 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:53,335] Trial 36 failed with value None.
[W 2023-08-14 16:19:53,314] Trial 48 failed with parameters: {'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 74.76 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder.py", line 19, in forward
    x = layer(x, mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 20, in forward
    return self.sublayer[1](x, self.feed_forward)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/layer_norm.py", line 17, in forward
    return self.a_2 * (x - mean) / (std + self.eps) + self.b_2
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 74.76 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:53,337] Trial 48 failed with value None.











  1%|          | 12/1257 [00:46<51:12,  2.47s/it][A[A[A[A[A[A[A[A[A[A[A[W 2023-08-14 16:19:53,329] Trial 11 failed with parameters: {'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 10.00 MiB (GPU 0; 79.15 GiB total capacity; 74.72 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/positional_encoding.py", line 27, in forward
    return self.dropout(x)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/dropout.py", line 54, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 807, in dropout
    else _VF.dropout(input, p, training))
RuntimeError: CUDA out of memory. Tried to allocate 10.00 MiB (GPU 0; 79.15 GiB total capacity; 74.72 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:53,412] Trial 11 failed with value None.
[W 2023-08-14 16:19:53,342] Trial 38 failed with parameters: {'N': 4, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 74.76 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 21, in forward
    x = layer(x, memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 22, in forward
    x = self.sublayer[0](x, lambda x: self.self_attn(
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 23, in <lambda>
    x, x, x, tgt_mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 14, in attention
    / math.sqrt(d_k)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 74.76 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:53,413] Trial 38 failed with value None.
[W 2023-08-14 16:19:53,333] Trial 18 failed with parameters: {'N': 4, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 74.72 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/embeddings.py", line 13, in forward
    return self.lut(x) * math.sqrt(self.d_model)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/sparse.py", line 114, in forward
    self.norm_type, self.scale_grad_by_freq, self.sparse)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 1484, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 74.72 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:53,470] Trial 18 failed with value None.
[W 2023-08-14 16:19:53,446] Trial 44 failed with parameters: {'N': 8, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 73.68 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 106, in train_epoch
    loss = loss_compute(out, trg_y, ntokens)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/simpleloss_compute.py", line 18, in __call__
    loss.backward()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 73.68 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:53,471] Trial 44 failed with value None.
[W 2023-08-14 16:19:53,450] Trial 35 failed with parameters: {'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 73.75 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/embeddings.py", line 13, in forward
    return self.lut(x) * math.sqrt(self.d_model)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 73.75 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:53,472] Trial 35 failed with value None.
[W 2023-08-14 16:19:53,514] Trial 16 failed with parameters: {'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 10.00 MiB (GPU 0; 79.15 GiB total capacity; 73.66 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/embeddings.py", line 13, in forward
    return self.lut(x) * math.sqrt(self.d_model)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/sparse.py", line 114, in forward
    self.norm_type, self.scale_grad_by_freq, self.sparse)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 1484, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: CUDA out of memory. Tried to allocate 10.00 MiB (GPU 0; 79.15 GiB total capacity; 73.66 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:53,514] Trial 16 failed with value None.
[W 2023-08-14 16:19:53,524] Trial 54 failed with parameters: {'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 73.66 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/embeddings.py", line 13, in forward
    return self.lut(x) * math.sqrt(self.d_model)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 73.66 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:53,525] Trial 54 failed with value None.
[W 2023-08-14 16:19:53,562] Trial 1 failed with parameters: {'N': 6, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 73.66 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/embeddings.py", line 13, in forward
    return self.lut(x) * math.sqrt(self.d_model)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 73.66 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:53,562] Trial 1 failed with value None.
[W 2023-08-14 16:19:53,583] Trial 42 failed with parameters: {'N': 10, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 73.66 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/embeddings.py", line 13, in forward
    return self.lut(x) * math.sqrt(self.d_model)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 73.66 GiB already allocated; 11.25 MiB free; 78.31 GiB reserved in total by PyTorch)
[W 2023-08-14 16:19:53,584] Trial 42 failed with value None.
Traceback (most recent call last):
  File "train.py", line 30, in <module>
    study.optimize(objective,n_jobs = -1)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/study.py", line 452, in optimize
    show_progress_bar=show_progress_bar,
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 103, in _optimize
    f.result()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 163, in _optimize_sequential
    frozen_trial = _run_trial(study, func, catch)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 251, in _run_trial
    raise func_err
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 223, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 105, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder.py", line 19, in forward
    x = layer(x, mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in forward
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in <lambda>
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 16, in attention
    scores = scores.masked_fill(mask == 0, -1e9)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 75.87 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)





















































                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






































                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















































                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















































                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A































                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A







































                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














































                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




































                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















































                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A























                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

































                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





































                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






























                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
































                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
























                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















































                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















































                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















































                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



































                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











































                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















































                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













































                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








































                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

























                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










































                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


































                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





























                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









































                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












































                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















                                                 [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  1%|          | 11/1257 [00:46<1:27:33,  4.22s/it]




















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A













                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A














[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











                                                  [A[A[A[A[A[A[A[A[A[A[A[A





















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A







































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










                                                 [A[A[A[A[A[A[A[A[A[A[A









                                                   [A[A[A[A[A[A[A[A[A[A








                                                  [A[A[A[A[A[A[A[A[A
















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  1%|          | 7/1257 [00:50<2:30:42,  7.23s/it]



















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 2/1257 [00:41<7:11:54, 20.65s/it]


















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 4/1257 [00:41<3:36:43, 10.38s/it]

















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











[A[A[A[A[A[A[A[A[A[A[A[A












[A[A[A[A[A[A[A[A[A[A[A[A[A













[A[A[A[A[A[A[A[A[A[A[A[A[A[A














[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










[A[A[A[A[A[A[A[A[A[A[A


                                                  [A[A[A




















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









[A[A[A[A[A[A[A[A[A[A








[A[A[A[A[A[A[A[A[A

                                                  [A[A





                                                  [A[A[A[A[A[A






                                                  [A[A[A[A[A[A[A



                                                  [A[A[A[A




                                                  [A[A[A[A[A







[A[A[A[A[A[A[A[A















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A







































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 5/1257 [00:51<3:32:59, 10.21s/it]
















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A







































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 3/1257 [00:41<4:52:16, 13.98s/it]















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A







































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 3/1257 [00:44<5:09:39, 14.82s/it]














































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










[A[A[A[A[A[A[A[A[A[A[A











[A[A[A[A[A[A[A[A[A[A[A[A












[A[A[A[A[A[A[A[A[A[A[A[A[A













[A[A[A[A[A[A[A[A[A[A[A[A[A[A









[A[A[A[A[A[A[A[A[A[A


















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A







































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








[A[A[A[A[A[A[A[A[A







[A[A[A[A[A[A[A[A






[A[A[A[A[A[A[A














[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  1%|          | 8/1257 [00:50<2:11:50,  6.33s/it]













































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A







































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 2/1257 [00:41<7:15:46, 20.83s/it]












































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A







































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 3/1257 [00:41<4:49:12, 13.84s/it]











































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A







































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 4/1257 [00:42<3:41:23, 10.60s/it]












































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 5/1257 [00:36<2:31:52,  7.28s/it]










































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A







































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 2/1257 [00:41<7:11:54, 20.65s/it]









































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A







































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 3/1257 [00:42<4:55:29, 14.14s/it]








































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  1%|          | 9/1257 [00:41<1:36:03,  4.62s/it]







































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A







































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 2/1257 [00:41<7:16:13, 20.86s/it]






































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  1%|          | 8/1257 [00:42<1:51:24,  5.35s/it]





































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 3/1257 [00:41<4:47:34, 13.76s/it]




































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 3/1257 [00:41<4:49:16, 13.84s/it]



































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 4/1257 [00:41<3:35:39, 10.33s/it]



































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 4/1257 [00:41<3:34:56, 10.29s/it]

































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 3/1257 [00:41<4:49:13, 13.84s/it]



























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 4/1257 [00:42<3:41:17, 10.60s/it]


























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









[A[A[A[A[A[A[A[A[A[A










[A[A[A[A[A[A[A[A[A[A[A











[A[A[A[A[A[A[A[A[A[A[A[A












[A[A[A[A[A[A[A[A[A[A[A[A[A








[A[A[A[A[A[A[A[A[A

















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A







[A[A[A[A[A[A[A[A






[A[A[A[A[A[A[A




[A[A[A[A[A



[A[A[A[A





[A[A[A[A[A[A













[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  1%|          | 7/1257 [00:50<2:31:14,  7.26s/it]

























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








[A[A[A[A[A[A[A[A[A









[A[A[A[A[A[A[A[A[A[A










[A[A[A[A[A[A[A[A[A[A[A











[A[A[A[A[A[A[A[A[A[A[A[A







[A[A[A[A[A[A[A[A
















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












[A[A[A[A[A[A[A[A[A[A[A[A[A















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  1%|          | 12/1257 [00:46<1:20:58,  3.90s/it]
























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A







[A[A[A[A[A[A[A[A








[A[A[A[A[A[A[A[A[A









[A[A[A[A[A[A[A[A[A[A










[A[A[A[A[A[A[A[A[A[A[A






[A[A[A[A[A[A[A















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












[A[A[A[A[A[A[A[A[A[A[A[A[A

















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













[A[A[A[A[A[A[A[A[A[A[A[A[A[A





[A[A[A[A[A[A



[A[A[A[A




[A[A[A[A[A











[A[A[A[A[A[A[A[A[A[A[A[A














[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 6/1257 [00:50<2:54:16,  8.36s/it]























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













[A[A[A[A[A[A[A[A[A[A[A[A[A[A  1%|          | 9/1257 [00:44<1:42:32,  4.93s/it]






















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






[A[A[A[A[A[A[A







[A[A[A[A[A[A[A[A








[A[A[A[A[A[A[A[A[A









[A[A[A[A[A[A[A[A[A[A





[A[A[A[A[A[A

[A[A













[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











[A[A[A[A[A[A[A[A[A[A[A[A















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




[A[A[A[A[A


[A[A[A



[A[A[A[A










[A[A[A[A[A[A[A[A[A[A[A












[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 6/1257 [00:50<2:55:02,  8.40s/it]


























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 3/1257 [00:41<4:48:05, 13.78s/it]
  0%|          | 2/1257 [00:35<6:11:56, 17.78s/it]

























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 3/1257 [00:41<4:48:10, 13.79s/it]





















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 4/1257 [00:42<3:43:46, 10.72s/it]




















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  1%|          | 7/1257 [00:41<2:03:44,  5.94s/it]



















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 4/1257 [00:41<3:39:13, 10.50s/it]


















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












[A[A[A[A[A[A[A[A[A[A[A[A[A














[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













[A[A[A[A[A[A[A[A[A[A[A[A[A[A















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











[A[A[A[A[A[A[A[A[A[A[A[A  1%|          | 9/1257 [00:44<1:43:01,  4.95s/it]




















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 4/1257 [00:41<3:35:23, 10.31s/it]

















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 4/1257 [00:41<3:38:11, 10.45s/it]
















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 2/1257 [00:41<7:18:31, 20.97s/it]















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











[A[A[A[A[A[A[A[A[A[A[A[A








[A[A[A[A[A[A[A[A[A












[A[A[A[A[A[A[A[A[A[A[A[A[A















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













[A[A[A[A[A[A[A[A[A[A[A[A[A[A









[A[A[A[A[A[A[A[A[A[A










[A[A[A[A[A[A[A[A[A[A[A  0%|          | 3/1257 [00:46<5:22:40, 15.44s/it]














[A[A[A[A[A[A[A[A[A[A[A[A[A[A















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










[A[A[A[A[A[A[A[A[A[A[A











[A[A[A[A[A[A[A[A[A[A[A[A














[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












[A[A[A[A[A[A[A[A[A[A[A[A[A









[A[A[A[A[A[A[A[A[A[A  0%|          | 4/1257 [00:44<3:53:17, 11.17s/it]















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 4/1257 [00:41<3:35:40, 10.33s/it]













[A[A[A[A[A[A[A[A[A[A[A[A[A













[A[A[A[A[A[A[A[A[A[A[A[A[A[A









[A[A[A[A[A[A[A[A[A[A







[A[A[A[A[A[A[A[A










[A[A[A[A[A[A[A[A[A[A[A











[A[A[A[A[A[A[A[A[A[A[A[A








[A[A[A[A[A[A[A[A[A  0%|          | 4/1257 [00:46<4:03:44, 11.67s/it]












[A[A[A[A[A[A[A[A[A[A[A[A












[A[A[A[A[A[A[A[A[A[A[A[A[A








[A[A[A[A[A[A[A[A[A






[A[A[A[A[A[A[A









[A[A[A[A[A[A[A[A[A[A










[A[A[A[A[A[A[A[A[A[A[A







[A[A[A[A[A[A[A[A  0%|          | 4/1257 [00:46<4:03:51, 11.68s/it]
  1%|          | 7/1257 [00:41<2:02:48,  5.89s/it]
  1%|          | 7/1257 [00:41<2:03:42,  5.94s/it]









[A[A[A[A[A[A[A[A[A









[A[A[A[A[A[A[A[A[A[A  1%|          | 7/1257 [00:42<2:06:10,  6.06s/it]






[A[A[A[A[A[A




[A[A[A[A[A
[A







[A[A[A[A[A[A[A[A








[A[A[A[A[A[A[A[A[A



[A[A[A[A

[A[A


[A[A[A






[A[A[A[A[A[A[A  0%|          | 6/1257 [00:50<2:55:29,  8.42s/it]





[A[A[A[A[A






[A[A[A[A[A[A[A







[A[A[A[A[A[A[A[A





[A[A[A[A[A[A  0%|          | 4/1257 [00:46<4:04:05, 11.69s/it]
  0%|          | 2/1257 [00:41<7:14:51, 20.79s/it]
  0%|          | 3/1257 [00:41<4:51:20, 13.94s/it]




[A[A[A[A


[A[A[A
[A

[A[A




[A[A[A[A[A  0%|          | 3/1257 [00:50<5:53:00, 16.89s/it]




[A[A[A[A  1%|          | 7/1257 [00:45<2:15:41,  6.51s/it]


[A[A


[A[A[A  1%|          | 7/1257 [00:50<2:30:18,  7.21s/it]


[A[A  1%|          | 10/1257 [00:49<1:42:35,  4.94s/it]

[A  0%|          | 6/1257 [00:50<2:56:15,  8.45s/it]
  1%|          | 11/1257 [00:44<1:23:26,  4.02s/it]
