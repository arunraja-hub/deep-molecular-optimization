[I 2023-08-14 16:01:47,338] A new study created in memory with name: transformer-original-source2target-optuna-study
16:02:55: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:02:58: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.5}
16:02:58: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.5}
16:03:03: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:03:03: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:03:03: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1}
16:03:12: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:12: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:12: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:12: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:12: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:12: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:12: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:12: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:12: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:12: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:12: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:12: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:12: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:12: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:12: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:12: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:13: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:03:13: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:03:13: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:03:13: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:03:13: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:03:13: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:03:13: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:03:13: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004}
16:03:13: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:13: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:13: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:13: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:13: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:13: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:13: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:13: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:13: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:14: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:14: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:14: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:14: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:14: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:14: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:14: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:14: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:14: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:14: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:15: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:15: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:15: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:15: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:15: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:15: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:15: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:15: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:15: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:15: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:15: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:16: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:16: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:16: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:16: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:16: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:16: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:16: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:16: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:03:16: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:03:16: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:03:16: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:16: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:16: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:16: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:16: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:16: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:16: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:16: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:16: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:16: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:16: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:16: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:16: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.1}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py:59: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(p)
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.
  warnings.warn(warning.format(ret))
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1}
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:17: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:18: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:19: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:20: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:26: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:26: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:25: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:31: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:29: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:30: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:27: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:28: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:32: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1}
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1}
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.get_model +47: INFO     Optuna current params:{'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004}
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:34: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:35: transformer_trainer.train +214: INFO     Training start
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
  0%|          | 0/2513 [00:00<?, ?it/s]16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1

  0%|          | 0/2513 [00:00<?, ?it/s][A16:03:37: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start


  0%|          | 0/2513 [00:00<?, ?it/s][A[A16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start
16:03:39: transformer_trainer.train +214: INFO     Training start



  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A




  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A





  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A






  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A







  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A



  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A








  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start










  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start











  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start
16:04:28: transformer_trainer.train +214: INFO     Training start












  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start













  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start





  0%|          | 1/2513 [00:47<33:02:19, 47.35s/it]16:04:29: transformer_trainer.train +214: INFO     Training start
[A[A[A[A[A16:04:29: transformer_trainer.train +214: INFO     Training start














  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start
16:04:29: transformer_trainer.train +214: INFO     Training start















  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 1/2513 [00:50<35:29:29, 50.86s/it]16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
16:04:30: transformer_trainer.train +214: INFO     Training start
















  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A







  0%|          | 1/2513 [00:47<33:15:28, 47.66s/it][A[A[A[A[A[A[A[A16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start

















  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

  0%|          | 1/2513 [00:51<35:42:25, 51.17s/it][A[A16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1


















  0%|          | 0/2513 [00:00<?, ?it/s]16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:31: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1





  0%|          | 2/2513 [00:51<23:58:15, 34.37s/it][A[A[A[A[A16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1

  0%|          | 1/2513 [00:54<37:42:53, 54.05s/it]16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
[A16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1



  0%|          | 1/2513 [00:51<36:04:08, 51.69s/it]16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
[A[A[A16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1




  0%|          | 1/2513 [00:49<34:30:45, 49.46s/it][A[A[A[A16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1








  0%|          | 2/2513 [00:50<23:51:33, 34.21s/it][A[A[A[A[A[A[A[A16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1



















16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
  0%|          | 0/2513 [00:00<?, ?it/s]16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1







  0%|          | 1/2513 [00:52<36:44:49, 52.66s/it][A[A[A[A[A[A[A16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start


16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
  0%|          | 2/2513 [00:54<25:42:53, 36.87s/it][A[A16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1




















16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
  0%|          | 0/2513 [00:00<?, ?it/s]16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
  0%|          | 2/2513 [00:55<25:52:37, 37.10s/it]16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start





















  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1








  0%|          | 3/2513 [00:52<17:02:35, 24.44s/it][A[A[A[A[A[A[A[A16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start






  0%|          | 1/2513 [00:53<37:18:05, 53.46s/it][A[A[A[A[A[A16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start






















  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1





16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
  0%|          | 3/2513 [00:54<17:23:54, 24.95s/it][A[A[A[A[A16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1



16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
  0%|          | 2/2513 [00:54<25:52:37, 37.10s/it][A[A[A16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1























16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start









  0%|          | 1/2513 [00:52<36:42:44, 52.61s/it][A[A[A[A[A[A[A[A[A16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
























  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start

























  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start

  0%|          | 2/2513 [00:57<27:10:40, 38.96s/it]16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
[A16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1


























16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start


















  0%|          | 1/2513 [00:06<4:07:36,  5.91s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1



























  0%|          | 0/2513 [00:00<?, ?it/s]16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:38: transformer_trainer.train +214: INFO     Training start
















  0%|          | 1/2513 [00:08<5:39:35,  8.11s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1





























  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start




























  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start






























  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start































  0%|          | 0/2513 [00:00<?, ?it/s]16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:34: transformer_trainer.train +214: INFO     Training start
[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:32: transformer_trainer.train +212: INFO     Starting EPOCH #1
16:04:37: transformer_trainer.train +214: INFO     Training start
































16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:33: transformer_trainer.train +214: INFO     Training start
  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start

































16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start


  0%|          | 3/2513 [01:00<18:57:15, 27.19s/it][A[A16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start


































16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
  0%|          | 0/2513 [00:00<?, ?it/s]16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start



































16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start








  0%|          | 4/2513 [00:59<13:04:54, 18.77s/it][A[A[A[A[A[A[A[A16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start





































16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start












16:04:35: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
  0%|          | 1/2513 [00:14<9:21:00, 13.40s/it][A[A[A[A[A[A[A[A[A[A[A[A16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:36: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start






































  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start







































  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start




































  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start









































16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
  0%|          | 0/2513 [00:00<?, ?it/s]16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start










































  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
  0%|          | 3/2513 [01:05<19:42:29, 28.27s/it]16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start








































  0%|          | 0/2513 [00:00<?, ?it/s]16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start





  0%|          | 4/2513 [01:03<13:23:10, 19.21s/it]16:04:39: transformer_trainer.train +214: INFO     Training start
[A[A[A[A[A16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start












































16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start













































16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start











































16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start




  0%|          | 2/2513 [01:02<26:39:20, 38.22s/it]16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
[A[A[A[A16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start

















  0%|          | 1/2513 [00:15<10:05:36, 14.47s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:37: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start














































16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start















































16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:38: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start
16:04:39: transformer_trainer.train +214: INFO     Training start

16:04:38: transformer_trainer.train +214: INFO     Training start
  0%|          | 3/2513 [01:08<21:09:33, 30.35s/it][A

















































  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A16:04:39: transformer_trainer.train +214: INFO     Training start
















































  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















































  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















































  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















































  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















































  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















































  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















































  0%|          | 0/2513 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












  0%|          | 1/2513 [00:22<15:44:12, 22.55s/it][A[A[A[A[A[A[A[A[A[A[A[A[A






  0%|          | 2/2513 [01:10<29:21:30, 42.09s/it][A[A[A[A[A[A[A


  0%|          | 3/2513 [01:11<21:33:33, 30.92s/it][A[A[A


















  0%|          | 1/2513 [00:21<14:46:49, 21.18s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

  0%|          | 4/2513 [01:16<16:52:04, 24.20s/it][A[A







  0%|          | 5/2513 [01:14<12:38:02, 18.14s/it][A[A[A[A[A[A[A[A



















  0%|          | 1/2513 [00:22<15:59:11, 22.91s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















  0%|          | 1/2513 [00:21<14:42:02, 21.07s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















  0%|          | 1/2513 [00:22<15:52:48, 22.76s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




  0%|          | 5/2513 [01:16<12:48:40, 18.39s/it][A[A[A[A[A










  0%|          | 1/2513 [00:30<21:36:42, 30.97s/it][A[A[A[A[A[A[A[A[A[A[A

















  0%|          | 2/2513 [00:27<7:21:34, 10.55s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









  0%|          | 1/2513 [00:31<21:52:12, 31.34s/it][A[A[A[A[A[A[A[A[A[A

























  0%|          | 1/2513 [00:22<15:21:28, 22.01s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
































  0%|          | 1/2513 [00:19<13:55:38, 19.96s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
























  0%|          | 1/2513 [00:22<15:56:21, 22.84s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















  0%|          | 2/2513 [00:29<8:26:09, 12.09s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















  0%|          | 1/2513 [00:23<16:37:18, 23.82s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













  0%|          | 1/2513 [00:31<21:41:20, 31.08s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A







  0%|          | 6/2513 [01:17<9:27:20, 13.58s/it] [A[A[A[A[A[A[A[A























  0%|          | 1/2513 [00:23<16:15:07, 23.29s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A































  0%|          | 1/2513 [00:22<15:32:43, 22.28s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















  0%|          | 2/2513 [00:27<11:44:52, 16.84s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
  0%|          | 4/2513 [01:22<17:50:40, 25.60s/it][A
















  0%|          | 2/2513 [00:31<10:32:51, 15.12s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























  0%|          | 1/2513 [00:23<16:16:18, 23.32s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








  0%|          | 2/2513 [01:18<31:04:25, 44.55s/it][A[A[A[A[A[A[A[A[A


























  0%|          | 1/2513 [00:23<16:39:46, 23.88s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



  0%|          | 3/2513 [01:18<22:15:37, 31.93s/it][A[A[A[A














  0%|          | 1/2513 [00:33<23:22:33, 33.50s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























  0%|          | 1/2513 [00:24<16:48:49, 24.10s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










































  0%|          | 1/2513 [00:16<11:39:28, 16.71s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






























  0%|          | 1/2513 [00:25<17:58:53, 25.77s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

  0%|          | 5/2513 [01:25<13:36:19, 19.53s/it][A[A






  0%|          | 3/2513 [01:23<23:17:50, 33.41s/it][A[A[A[A[A[A[A  0%|          | 4/2513 [01:26<18:35:01, 26.66s/it]




















































  0%|          | 1/2513 [00:17<12:03:50, 17.29s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





























  0%|          | 1/2513 [00:26<18:40:06, 26.75s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


  0%|          | 4/2513 [01:24<17:45:40, 25.48s/it][A[A[A







  0%|          | 7/2513 [01:22<7:46:57, 11.18s/it][A[A[A[A[A[A[A[A




  0%|          | 6/2513 [01:24<10:30:58, 15.10s/it][A[A[A[A[A





  0%|          | 2/2513 [01:24<32:31:30, 46.63s/it][A[A[A[A[A[A
















































  0%|          | 1/2513 [00:18<13:02:58, 18.70s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





































  0%|          | 1/2513 [00:24<17:01:33, 24.40s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











  0%|          | 2/2513 [00:38<11:48:34, 16.93s/it][A[A[A[A[A[A[A[A[A[A[A[A




















  0%|          | 2/2513 [00:32<13:06:06, 18.78s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















































  0%|          | 1/2513 [00:18<13:12:59, 18.94s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















































  0%|          | 1/2513 [00:20<14:20:26, 20.55s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



































  0%|          | 1/2513 [00:26<18:13:56, 26.13s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















  0%|          | 2/2513 [00:32<12:46:34, 18.32s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









































  0%|          | 1/2513 [00:25<17:59:58, 25.80s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






































  0%|          | 1/2513 [00:26<18:46:13, 26.90s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




































  0%|          | 1/2513 [00:27<19:15:38, 27.60s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

























  0%|          | 2/2513 [00:32<12:50:20, 18.41s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
































  0%|          | 2/2513 [00:30<11:50:46, 16.98s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















  0%|          | 2/2513 [00:33<13:40:55, 19.62s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















































  0%|          | 1/2513 [00:22<15:31:45, 22.26s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













































  0%|          | 1/2513 [00:22<15:55:22, 22.82s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
  0%|          | 5/2513 [01:30<14:11:10, 20.36s/it][A












































  0%|          | 1/2513 [00:25<17:48:57, 25.53s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















  0%|          | 3/2513 [00:39<7:42:03, 11.05s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A























  0%|          | 2/2513 [00:34<13:49:04, 19.81s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








































  0%|          | 1/2513 [00:28<19:43:28, 28.27s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











































  0%|          | 1/2513 [00:27<19:12:16, 27.52s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A







































  0%|          | 1/2513 [00:28<19:37:39, 28.13s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














































  0%|          | 1/2513 [00:25<17:48:40, 25.53s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















  0%|          | 2/2513 [00:38<14:23:12, 20.63s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A































  0%|          | 2/2513 [00:33<13:14:24, 18.98s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















  0%|          | 3/2513 [00:42<9:43:05, 13.94s/it] [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

































  0%|          | 1/2513 [00:33<23:31:48, 33.72s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























  0%|          | 2/2513 [00:36<14:04:09, 20.17s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
























  0%|          | 2/2513 [00:37<14:19:19, 20.53s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























  0%|          | 2/2513 [00:36<14:17:31, 20.49s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















  0%|          | 3/2513 [00:44<9:05:07, 13.03s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


































  0%|          | 1/2513 [00:33<23:33:27, 33.76s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 5/2513 [01:36<15:07:53, 21.72s/it]




  0%|          | 7/2513 [01:33<9:24:39, 13.52s/it] [A[A[A[A[A[W 2023-08-14 16:05:14,300] Trial 18 failed with parameters: {'N': 6, 'd_model': 512, 'd_ff': 256, 'h': 8, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 76.17 GiB already allocated; 7.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 21, in forward
    x = layer(x, memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 24, in forward
    x = self.sublayer[1](x, lambda x: self.src_attn(
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 25, in <lambda>
    x, m, m, src_mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 55, in forward
    return self.linears[-1](x)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 1372, in linear
    output = input.matmul(weight.t())
RuntimeError: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 76.17 GiB already allocated; 7.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:14,399] Trial 20 failed with parameters: {'N': 4, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 79.15 GiB total capacity; 76.17 GiB already allocated; 7.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder.py", line 19, in forward
    x = layer(x, mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in forward
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in <lambda>
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 17, in attention
    p_attn = F.softmax(scores, dim=-1)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 79.15 GiB total capacity; 76.17 GiB already allocated; 7.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,115] Trial 20 failed with value None.
[W 2023-08-14 16:05:14,436] Trial 53 failed with parameters: {'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 79.15 GiB total capacity; 76.17 GiB already allocated; 7.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 21, in forward
    x = layer(x, memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 24, in forward
    x = self.sublayer[1](x, lambda x: self.src_attn(
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 25, in <lambda>
    x, m, m, src_mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 14, in attention
    / math.sqrt(d_k)
RuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 79.15 GiB total capacity; 76.17 GiB already allocated; 7.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:14,462] Trial 39 failed with parameters: {'N': 10, 'd_model': 512, 'd_ff': 256, 'h': 4, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.16 GiB already allocated; 7.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 21, in forward
    x = layer(x, memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 22, in forward
    x = self.sublayer[0](x, lambda x: self.self_attn(
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 23, in <lambda>
    x, x, x, tgt_mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 45, in forward
    for l, x in zip(self.linears, (query, key, value))]
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 45, in <listcomp>
    for l, x in zip(self.linears, (query, key, value))]
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 1372, in linear
    output = input.matmul(weight.t())
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.16 GiB already allocated; 7.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,154] Trial 39 failed with value None.
[W 2023-08-14 16:05:14,494] Trial 52 failed with parameters: {'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.17 GiB already allocated; 7.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder.py", line 19, in forward
    x = layer(x, mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 20, in forward
    return self.sublayer[1](x, self.feed_forward)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/positionwise_feedforward.py", line 15, in forward
    return self.w_2(self.dropout(F.relu(self.w_1(x))))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/dropout.py", line 54, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 807, in dropout
    else _VF.dropout(input, p, training))
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.17 GiB already allocated; 7.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,185] Trial 52 failed with value None.
[W 2023-08-14 16:05:14,522] Trial 38 failed with parameters: {'N': 4, 'd_model': 64, 'd_ff': 512, 'h': 16, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 76.15 GiB already allocated; 7.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 21, in forward
    x = layer(x, memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 24, in forward
    x = self.sublayer[1](x, lambda x: self.src_attn(
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/layer_norm.py", line 17, in forward
    return self.a_2 * (x - mean) / (std + self.eps) + self.b_2
RuntimeError: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 76.15 GiB already allocated; 7.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,192] Trial 38 failed with value None.
[W 2023-08-14 16:05:14,605] Trial 41 failed with parameters: {'N': 2, 'd_model': 64, 'd_ff': 2048, 'h': 16, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 76.20 GiB already allocated; 7.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder.py", line 20, in forward
    return self.norm(x)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/layer_norm.py", line 17, in forward
    return self.a_2 * (x - mean) / (std + self.eps) + self.b_2
RuntimeError: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 76.20 GiB already allocated; 7.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,193] Trial 41 failed with value None.
[W 2023-08-14 16:05:14,670] Trial 3 failed with parameters: {'N': 6, 'd_model': 128, 'd_ff': 2048, 'h': 8, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 38.00 MiB (GPU 0; 79.15 GiB total capacity; 76.21 GiB already allocated; 25.25 MiB free; 78.30 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 21, in forward
    x = layer(x, memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 22, in forward
    x = self.sublayer[0](x, lambda x: self.self_attn(
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 23, in <lambda>
    x, x, x, tgt_mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 13, in attention
    scores = torch.matmul(query, key.transpose(-2, -1)) \
RuntimeError: CUDA out of memory. Tried to allocate 38.00 MiB (GPU 0; 79.15 GiB total capacity; 76.21 GiB already allocated; 25.25 MiB free; 78.30 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,194] Trial 3 failed with value None.
[W 2023-08-14 16:05:14,701] Trial 47 failed with parameters: {'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 4, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 76.22 GiB already allocated; 7.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 21, in forward
    x = layer(x, memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 27, in forward
    return self.sublayer[2](x, self.feed_forward)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/layer_norm.py", line 17, in forward
    return self.a_2 * (x - mean) / (std + self.eps) + self.b_2
RuntimeError: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 76.22 GiB already allocated; 7.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,199] Trial 47 failed with value None.
[W 2023-08-14 16:05:14,833] Trial 19 failed with parameters: {'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 76.23 GiB already allocated; 5.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 21, in forward
    x = layer(x, memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 22, in forward
    x = self.sublayer[0](x, lambda x: self.self_attn(
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 23, in <lambda>
    x, x, x, tgt_mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 52, in forward
    x = x.transpose(1, 2).contiguous() \
RuntimeError: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 76.23 GiB already allocated; 5.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,200] Trial 19 failed with value None.
[W 2023-08-14 16:05:14,862] Trial 32 failed with parameters: {'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.23 GiB already allocated; 5.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 21, in forward
    x = layer(x, memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 22, in forward
    x = self.sublayer[0](x, lambda x: self.self_attn(
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 23, in <lambda>
    x, x, x, tgt_mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 19, in attention
    p_attn = dropout(p_attn)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/dropout.py", line 54, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 807, in dropout
    else _VF.dropout(input, p, training))
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.23 GiB already allocated; 5.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,201] Trial 32 failed with value None.
[W 2023-08-14 16:05:14,897] Trial 49 failed with parameters: {'N': 8, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.23 GiB already allocated; 5.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 21, in forward
    x = layer(x, memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 24, in forward
    x = self.sublayer[1](x, lambda x: self.src_attn(
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 25, in <lambda>
    x, m, m, src_mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 45, in forward
    for l, x in zip(self.linears, (query, key, value))]
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 45, in <listcomp>
    for l, x in zip(self.linears, (query, key, value))]
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 1372, in linear
    output = input.matmul(weight.t())
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.23 GiB already allocated; 5.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,205] Trial 49 failed with value None.
[W 2023-08-14 16:05:15,143] Trial 1 failed with parameters: {'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.27 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 21, in forward
    x = layer(x, memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 24, in forward
    x = self.sublayer[1](x, lambda x: self.src_attn(
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 25, in <lambda>
    x, m, m, src_mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 13, in attention
    scores = torch.matmul(query, key.transpose(-2, -1)) \
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.27 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:15,248] Trial 22 failed with parameters: {'N': 2, 'd_model': 512, 'd_ff': 256, 'h': 16, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 79.15 GiB total capacity; 76.27 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 104, in train_epoch
    loss = loss_compute(out, trg_y, ntokens)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/simpleloss_compute.py", line 19, in __call__
    self.opt.step()
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/noam_opt.py", line 20, in step
    self.optimizer.step()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/optim/adam.py", line 103, in step
    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 79.15 GiB total capacity; 76.27 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,316] Trial 22 failed with value None.
[W 2023-08-14 16:05:15,179] Trial 13 failed with parameters: {'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 8, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 79.15 GiB total capacity; 76.27 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 104, in train_epoch
    loss = loss_compute(out, trg_y, ntokens)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/simpleloss_compute.py", line 19, in __call__
    self.opt.step()
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/noam_opt.py", line 20, in step
    self.optimizer.step()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/optim/adam.py", line 77, in step
    state['exp_avg_sq'] = torch.zeros_like(p.data, memory_format=torch.preserve_format)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 79.15 GiB total capacity; 76.27 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:15,444] Trial 27 failed with parameters: {'N': 6, 'd_model': 128, 'd_ff': 512, 'h': 4, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 104, in train_epoch
    loss = loss_compute(out, trg_y, ntokens)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/simpleloss_compute.py", line 19, in __call__
    self.opt.step()
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/noam_opt.py", line 20, in step
    self.optimizer.step()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/optim/adam.py", line 103, in step
    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,317] Trial 27 failed with value None.
[W 2023-08-14 16:05:15,471] Trial 4 failed with parameters: {'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 100, in train_epoch
    trg_mask = trg_mask.to(device)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:15,498] Trial 21 failed with parameters: {'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 4, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.26 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/embeddings.py", line 13, in forward
    return self.lut(x) * math.sqrt(self.d_model)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/sparse.py", line 114, in forward
    self.norm_type, self.scale_grad_by_freq, self.sparse)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 1484, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.26 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:15,511] Trial 46 failed with parameters: {'N': 4, 'd_model': 512, 'd_ff': 512, 'h': 4, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 104, in train_epoch
    loss = loss_compute(out, trg_y, ntokens)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/simpleloss_compute.py", line 19, in __call__
    self.opt.step()
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/noam_opt.py", line 20, in step
    self.optimizer.step()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/optim/adam.py", line 103, in step
    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,364] Trial 46 failed with value None.
[W 2023-08-14 16:05:15,534] Trial 15 failed with parameters: {'N': 10, 'd_model': 64, 'd_ff': 256, 'h': 8, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 104, in train_epoch
    loss = loss_compute(out, trg_y, ntokens)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/simpleloss_compute.py", line 19, in __call__
    self.opt.step()
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/noam_opt.py", line 20, in step
    self.optimizer.step()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/optim/adam.py", line 103, in step
    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:15,602] Trial 44 failed with parameters: {'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.26 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/embeddings.py", line 13, in forward
    return self.lut(x) * math.sqrt(self.d_model)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/sparse.py", line 114, in forward
    self.norm_type, self.scale_grad_by_freq, self.sparse)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 1484, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.26 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:15,613] Trial 2 failed with parameters: {'N': 10, 'd_model': 64, 'd_ff': 512, 'h': 8, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 79.15 GiB total capacity; 76.26 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 21, in forward
    x = layer(x, memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 24, in forward
    x = self.sublayer[1](x, lambda x: self.src_attn(
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 25, in <lambda>
    x, m, m, src_mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 13, in attention
    scores = torch.matmul(query, key.transpose(-2, -1)) \
RuntimeError: CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 79.15 GiB total capacity; 76.26 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,373] Trial 2 failed with value None.
[W 2023-08-14 16:05:15,749] Trial 5 failed with parameters: {'N': 8, 'd_model': 256, 'd_ff': 2048, 'h': 8, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 79.15 GiB total capacity; 76.26 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 104, in train_epoch
    loss = loss_compute(out, trg_y, ntokens)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/simpleloss_compute.py", line 19, in __call__
    self.opt.step()
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/noam_opt.py", line 20, in step
    self.optimizer.step()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/optim/adam.py", line 103, in step
    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 79.15 GiB total capacity; 76.26 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,374] Trial 5 failed with value None.
[W 2023-08-14 16:05:15,971] Trial 18 failed with value None.
[W 2023-08-14 16:05:15,971] Trial 28 failed with parameters: {'N': 6, 'd_model': 256, 'd_ff': 512, 'h': 4, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 79.15 GiB total capacity; 76.26 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 104, in train_epoch
    loss = loss_compute(out, trg_y, ntokens)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/simpleloss_compute.py", line 19, in __call__
    self.opt.step()
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/noam_opt.py", line 20, in step
    self.optimizer.step()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/optim/adam.py", line 103, in step
    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 79.15 GiB total capacity; 76.26 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,377] Trial 28 failed with value None.
[W 2023-08-14 16:05:15,974] Trial 6 failed with parameters: {'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 104, in train_epoch
    loss = loss_compute(out, trg_y, ntokens)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/simpleloss_compute.py", line 19, in __call__
    self.opt.step()
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/noam_opt.py", line 20, in step
    self.optimizer.step()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/optim/adam.py", line 103, in step
    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,384] Trial 6 failed with value None.
[W 2023-08-14 16:05:16,014] Trial 51 failed with parameters: {'N': 6, 'd_model': 512, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/embeddings.py", line 13, in forward
    return self.lut(x) * math.sqrt(self.d_model)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/sparse.py", line 114, in forward
    self.norm_type, self.scale_grad_by_freq, self.sparse)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 1484, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,384] Trial 51 failed with value None.
[W 2023-08-14 16:05:16,067] Trial 54 failed with parameters: {'N': 8, 'd_model': 256, 'd_ff': 512, 'h': 8, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 76.26 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/embeddings.py", line 13, in forward
    return self.lut(x) * math.sqrt(self.d_model)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/sparse.py", line 114, in forward
    self.norm_type, self.scale_grad_by_freq, self.sparse)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 1484, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 76.26 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,385] Trial 54 failed with value None.
[W 2023-08-14 16:05:16,101] Trial 23 failed with parameters: {'N': 6, 'd_model': 64, 'd_ff': 256, 'h': 16, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/embeddings.py", line 13, in forward
    return self.lut(x) * math.sqrt(self.d_model)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/sparse.py", line 114, in forward
    self.norm_type, self.scale_grad_by_freq, self.sparse)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 1484, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,388] Trial 23 failed with value None.
[W 2023-08-14 16:05:14,433] Trial 48 failed with parameters: {'N': 2, 'd_model': 256, 'd_ff': 256, 'h': 16, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 76.17 GiB already allocated; 7.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder.py", line 19, in forward
    x = layer(x, mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in forward
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in <lambda>
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 20, in attention
    return torch.matmul(p_attn, value), p_attn
RuntimeError: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 76.17 GiB already allocated; 7.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,389] Trial 48 failed with value None.
[W 2023-08-14 16:05:14,602] Trial 37 failed with parameters: {'N': 8, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.20 GiB already allocated; 7.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 21, in forward
    x = layer(x, memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 24, in forward
    x = self.sublayer[1](x, lambda x: self.src_attn(
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 25, in <lambda>
    x, m, m, src_mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 20, in attention
    return torch.matmul(p_attn, value), p_attn
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.20 GiB already allocated; 7.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,390] Trial 37 failed with value None.
[W 2023-08-14 16:05:14,627] Trial 34 failed with parameters: {'N': 2, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.17 GiB already allocated; 7.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder.py", line 19, in forward
    x = layer(x, mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 20, in forward
    return self.sublayer[1](x, self.feed_forward)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/positionwise_feedforward.py", line 15, in forward
    return self.w_2(self.dropout(F.relu(self.w_1(x))))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 1372, in linear
    output = input.matmul(weight.t())
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.17 GiB already allocated; 7.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,390] Trial 34 failed with value None.
[W 2023-08-14 16:05:14,649] Trial 30 failed with parameters: {'N': 2, 'd_model': 128, 'd_ff': 1024, 'h': 16, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.17 GiB already allocated; 7.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 21, in forward
    x = layer(x, memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 22, in forward
    x = self.sublayer[0](x, lambda x: self.self_attn(
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 23, in <lambda>
    x, x, x, tgt_mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 20, in attention
    return torch.matmul(p_attn, value), p_attn
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.17 GiB already allocated; 7.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,395] Trial 30 failed with value None.
[W 2023-08-14 16:05:14,845] Trial 17 failed with parameters: {'N': 10, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.23 GiB already allocated; 5.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 21, in forward
    x = layer(x, memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 27, in forward
    return self.sublayer[2](x, self.feed_forward)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/positionwise_feedforward.py", line 15, in forward
    return self.w_2(self.dropout(F.relu(self.w_1(x))))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 914, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.23 GiB already allocated; 5.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,397] Trial 17 failed with value None.
[W 2023-08-14 16:05:14,993] Trial 36 failed with parameters: {'N': 4, 'd_model': 64, 'd_ff': 1024, 'h': 16, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.27 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 21, in forward
    x = layer(x, memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 24, in forward
    x = self.sublayer[1](x, lambda x: self.src_attn(
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 25, in <lambda>
    x, m, m, src_mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 13, in attention
    scores = torch.matmul(query, key.transpose(-2, -1)) \
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.27 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,397] Trial 36 failed with value None.
[W 2023-08-14 16:05:16,238] Trial 26 failed with parameters: {'N': 6, 'd_model': 512, 'd_ff': 1024, 'h': 16, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/embeddings.py", line 13, in forward
    return self.lut(x) * math.sqrt(self.d_model)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/sparse.py", line 114, in forward
    self.norm_type, self.scale_grad_by_freq, self.sparse)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 1484, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,398] Trial 26 failed with value None.
[W 2023-08-14 16:05:16,225] Trial 55 failed with parameters: {'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/embeddings.py", line 13, in forward
    return self.lut(x) * math.sqrt(self.d_model)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/sparse.py", line 114, in forward
    self.norm_type, self.scale_grad_by_freq, self.sparse)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 1484, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,399] Trial 55 failed with value None.
[W 2023-08-14 16:05:16,317] Trial 13 failed with value None.
[W 2023-08-14 16:05:16,320] Trial 4 failed with value None.
[W 2023-08-14 16:05:16,363] Trial 21 failed with value None.
[W 2023-08-14 16:05:15,543] Trial 7 failed with parameters: {'N': 10, 'd_model': 256, 'd_ff': 256, 'h': 4, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 76.26 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 21, in forward
    x = layer(x, memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 27, in forward
    return self.sublayer[2](x, self.feed_forward)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/positionwise_feedforward.py", line 15, in forward
    return self.w_2(self.dropout(F.relu(self.w_1(x))))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 1372, in linear
    output = input.matmul(weight.t())
RuntimeError: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 76.26 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,406] Trial 7 failed with value None.
[W 2023-08-14 16:05:16,364] Trial 15 failed with value None.
[W 2023-08-14 16:05:15,814] Trial 24 failed with parameters: {'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 79.15 GiB total capacity; 76.26 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 104, in train_epoch
    loss = loss_compute(out, trg_y, ntokens)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/simpleloss_compute.py", line 19, in __call__
    self.opt.step()
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/noam_opt.py", line 20, in step
    self.optimizer.step()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/optim/adam.py", line 75, in step
    state['exp_avg'] = torch.zeros_like(p.data, memory_format=torch.preserve_format)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 79.15 GiB total capacity; 76.26 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:15,814] Trial 14 failed with parameters: {'N': 6, 'd_model': 128, 'd_ff': 1024, 'h': 8, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 79.15 GiB total capacity; 76.26 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 104, in train_epoch
    loss = loss_compute(out, trg_y, ntokens)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/simpleloss_compute.py", line 19, in __call__
    self.opt.step()
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/noam_opt.py", line 20, in step
    self.optimizer.step()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/optim/adam.py", line 103, in step
    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 79.15 GiB total capacity; 76.26 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,520] Trial 14 failed with value None.
[W 2023-08-14 16:05:16,377] Trial 43 failed with parameters: {'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 4, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/embeddings.py", line 13, in forward
    return self.lut(x) * math.sqrt(self.d_model)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/sparse.py", line 114, in forward
    self.norm_type, self.scale_grad_by_freq, self.sparse)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 1484, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,521] Trial 43 failed with value None.
[W 2023-08-14 16:05:16,003] Trial 9 failed with parameters: {'N': 4, 'd_model': 128, 'd_ff': 256, 'h': 8, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 79.15 GiB total capacity; 76.26 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 104, in train_epoch
    loss = loss_compute(out, trg_y, ntokens)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/simpleloss_compute.py", line 19, in __call__
    self.opt.step()
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/noam_opt.py", line 20, in step
    self.optimizer.step()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/optim/adam.py", line 103, in step
    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 79.15 GiB total capacity; 76.26 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,077] Trial 42 failed with parameters: {'N': 10, 'd_model': 128, 'd_ff': 256, 'h': 16, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/embeddings.py", line 13, in forward
    return self.lut(x) * math.sqrt(self.d_model)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/sparse.py", line 114, in forward
    self.norm_type, self.scale_grad_by_freq, self.sparse)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 1484, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,522] Trial 42 failed with value None.
[W 2023-08-14 16:05:16,138] Trial 53 failed with value None.
[W 2023-08-14 16:05:14,722] Trial 40 failed with parameters: {'N': 8, 'd_model': 256, 'd_ff': 1024, 'h': 16, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 76.22 GiB already allocated; 7.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 21, in forward
    x = layer(x, memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 27, in forward
    return self.sublayer[2](x, self.feed_forward)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/positionwise_feedforward.py", line 15, in forward
    return self.w_2(self.dropout(F.relu(self.w_1(x))))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/dropout.py", line 54, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 807, in dropout
    else _VF.dropout(input, p, training))
RuntimeError: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 76.22 GiB already allocated; 7.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,522] Trial 40 failed with value None.
[W 2023-08-14 16:05:16,394] Trial 35 failed with parameters: {'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/embeddings.py", line 13, in forward
    return self.lut(x) * math.sqrt(self.d_model)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/sparse.py", line 114, in forward
    self.norm_type, self.scale_grad_by_freq, self.sparse)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 1484, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:15,005] Trial 29 failed with parameters: {'N': 6, 'd_model': 256, 'd_ff': 1024, 'h': 4, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 79.15 GiB total capacity; 76.26 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 104, in train_epoch
    loss = loss_compute(out, trg_y, ntokens)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/simpleloss_compute.py", line 19, in __call__
    self.opt.step()
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/noam_opt.py", line 20, in step
    self.optimizer.step()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/optim/adam.py", line 103, in step
    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 79.15 GiB total capacity; 76.26 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,523] Trial 29 failed with value None.
[W 2023-08-14 16:05:15,309] Trial 33 failed with parameters: {'N': 4, 'd_model': 512, 'd_ff': 2048, 'h': 4, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 79.15 GiB total capacity; 76.27 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 104, in train_epoch
    loss = loss_compute(out, trg_y, ntokens)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/simpleloss_compute.py", line 19, in __call__
    self.opt.step()
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/noam_opt.py", line 20, in step
    self.optimizer.step()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/optim/adam.py", line 103, in step
    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 79.15 GiB total capacity; 76.27 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,251] Trial 25 failed with parameters: {'N': 4, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/embeddings.py", line 13, in forward
    return self.lut(x) * math.sqrt(self.d_model)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/sparse.py", line 114, in forward
    self.norm_type, self.scale_grad_by_freq, self.sparse)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 1484, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:15,482] Trial 31 failed with parameters: {'N': 10, 'd_model': 128, 'd_ff': 512, 'h': 16, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/embeddings.py", line 13, in forward
    return self.lut(x) * math.sqrt(self.d_model)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/sparse.py", line 114, in forward
    self.norm_type, self.scale_grad_by_freq, self.sparse)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 1484, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,524] Trial 31 failed with value None.
[W 2023-08-14 16:05:16,365] Trial 44 failed with value None.
[W 2023-08-14 16:05:16,520] Trial 24 failed with value None.
[W 2023-08-14 16:05:16,023] Trial 50 failed with parameters: {'N': 10, 'd_model': 128, 'd_ff': 2048, 'h': 16, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.26 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/embeddings.py", line 13, in forward
    return self.lut(x) * math.sqrt(self.d_model)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/sparse.py", line 114, in forward
    self.norm_type, self.scale_grad_by_freq, self.sparse)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 1484, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.26 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,535] Trial 50 failed with value None.
[W 2023-08-14 16:05:16,031] Trial 11 failed with parameters: {'N': 2, 'd_model': 128, 'd_ff': 512, 'h': 8, 'dropout': 0.30000000000000004} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/embeddings.py", line 13, in forward
    return self.lut(x) * math.sqrt(self.d_model)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/sparse.py", line 114, in forward
    self.norm_type, self.scale_grad_by_freq, self.sparse)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 1484, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:14,522] Trial 45 failed with parameters: {'N': 10, 'd_model': 64, 'd_ff': 2048, 'h': 8, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.13 GiB already allocated; 7.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder.py", line 19, in forward
    x = layer(x, mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in forward
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in <lambda>
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 45, in forward
    for l, x in zip(self.linears, (query, key, value))]
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 45, in <listcomp>
    for l, x in zip(self.linears, (query, key, value))]
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 1372, in linear
    output = input.matmul(weight.t())
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.13 GiB already allocated; 7.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:14,764] Trial 16 failed with parameters: {'N': 2, 'd_model': 128, 'd_ff': 2048, 'h': 4, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 76.23 GiB already allocated; 7.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 31, in forward
    tgt, tgt_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 37, in decode
    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder.py", line 21, in forward
    x = layer(x, memory, src_mask, tgt_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 22, in forward
    x = self.sublayer[0](x, lambda x: self.self_attn(
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/decoder_layer.py", line 23, in <lambda>
    x, x, x, tgt_mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 13, in attention
    scores = torch.matmul(query, key.transpose(-2, -1)) \
RuntimeError: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 79.15 GiB total capacity; 76.23 GiB already allocated; 7.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,537] Trial 16 failed with value None.
[W 2023-08-14 16:05:16,209] Trial 1 failed with value None.
[W 2023-08-14 16:05:16,524] Trial 33 failed with value None.
[W 2023-08-14 16:05:16,524] Trial 25 failed with value None.
[W 2023-08-14 16:05:16,514] Trial 12 failed with parameters: {'N': 8, 'd_model': 64, 'd_ff': 1024, 'h': 4, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/embeddings.py", line 13, in forward
    return self.lut(x) * math.sqrt(self.d_model)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/sparse.py", line 114, in forward
    self.norm_type, self.scale_grad_by_freq, self.sparse)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 1484, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,521] Trial 9 failed with value None.
[W 2023-08-14 16:05:16,536] Trial 11 failed with value None.
[W 2023-08-14 16:05:16,536] Trial 45 failed with value None.
[W 2023-08-14 16:05:16,523] Trial 35 failed with value None.
[W 2023-08-14 16:05:16,538] Trial 12 failed with value None.
[W 2023-08-14 16:05:16,545] Trial 10 failed with parameters: {'N': 2, 'd_model': 512, 'd_ff': 2048, 'h': 16, 'dropout': 0.1} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/embeddings.py", line 13, in forward
    return self.lut(x) * math.sqrt(self.d_model)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/sparse.py", line 114, in forward
    self.norm_type, self.scale_grad_by_freq, self.sparse)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 1484, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.15 GiB total capacity; 76.25 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,578] Trial 10 failed with value None.
[W 2023-08-14 16:05:16,612] Trial 0 failed with parameters: {'N': 2, 'd_model': 64, 'd_ff': 256, 'h': 4, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 79.15 GiB total capacity; 76.27 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder.py", line 19, in forward
    x = layer(x, mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in forward
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in <lambda>
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 13, in attention
    scores = torch.matmul(query, key.transpose(-2, -1)) \
RuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 79.15 GiB total capacity; 76.27 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,612] Trial 0 failed with value None.
[W 2023-08-14 16:05:16,617] Trial 8 failed with parameters: {'N': 4, 'd_model': 256, 'd_ff': 2048, 'h': 16, 'dropout': 0.5} because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 79.15 GiB total capacity; 76.32 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)').
Traceback (most recent call last):
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder.py", line 19, in forward
    x = layer(x, mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in forward
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in <lambda>
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 13, in attention
    scores = torch.matmul(query, key.transpose(-2, -1)) \
RuntimeError: CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 79.15 GiB total capacity; 76.32 GiB already allocated; 3.25 MiB free; 78.32 GiB reserved in total by PyTorch)
[W 2023-08-14 16:05:16,617] Trial 8 failed with value None.
Traceback (most recent call last):
  File "train.py", line 30, in <module>
    study.optimize(objective,n_jobs = -1)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/study.py", line 452, in optimize
    show_progress_bar=show_progress_bar,
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 103, in _optimize
    f.result()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 163, in _optimize_sequential
    frozen_trial = _run_trial(study, func, catch)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 251, in _run_trial
    raise func_err
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 22, in objective
    loss_epoch_train, loss_epoch_validation, accuracy = trainer.train(opt=opt,trial=trial)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 221, in train
    optim), device)
  File "/vols/opig/users/raja/deep-molecular-optimization/trainer/transformer_trainer.py", line 103, in train_epoch
    out = model.forward(src, trg, src_mask, trg_mask)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 30, in forward
    return self.decode(self.encode(src, src_mask), src_mask,
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/model.py", line 34, in encode
    return self.encoder(self.src_embed(src), src_mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder.py", line 19, in forward
    x = layer(x, mask)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in forward
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/sublayer_connection.py", line 18, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/encode_decode/encoder_layer.py", line 19, in <lambda>
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 49, in forward
    dropout=self.dropout)
  File "/vols/opig/users/raja/deep-molecular-optimization/models/transformer/module/multi_headed_attention.py", line 17, in attention
    p_attn = F.softmax(scores, dim=-1)
  File "/vols/opig/users/raja/miniconda3/envs/molopt/lib/python3.7/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 79.15 GiB total capacity; 76.17 GiB already allocated; 7.25 MiB free; 78.32 GiB reserved in total by PyTorch)





















































                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















































                                        [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















































                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















































                                        [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















































                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















































                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














































                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















































                                        [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















































                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 1/2513 [00:29<20:27:51, 29.33s/it]




















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












































                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A







































                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





































                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











































                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









































                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








































                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










































                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






































                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 1/2513 [00:34<23:52:39, 34.22s/it]



















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

































                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A























                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

























                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A































                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
































                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


































                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





























                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















                                                  [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
























                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



































                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A







































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






























                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 1/2513 [00:47<32:58:05, 47.25s/it]


















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 1/2513 [00:30<21:08:54, 30.31s/it]

















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 1/2513 [00:28<20:04:44, 28.78s/it]
















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A







































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 1/2513 [00:32<22:44:48, 32.60s/it]















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A







































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 2/2513 [00:41<14:25:24, 20.68s/it]














































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 0/2513 [00:28<?, ?it/s]













































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 1/2513 [00:29<20:14:39, 29.01s/it]














































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 1/2513 [00:27<19:07:46, 27.42s/it]












































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A







































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 1/2513 [00:33<23:22:35, 33.50s/it]











































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A







































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 2/2513 [00:39<13:45:10, 19.72s/it]










































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











                                                   [A[A[A[A[A[A[A[A[A[A[A[A













                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A[A




























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A







































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












                                                   [A[A[A[A[A[A[A[A[A[A[A[A[A














[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 1/2513 [00:48<33:50:07, 48.49s/it]









































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A







































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 1/2513 [00:31<21:47:58, 31.24s/it]








































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A








































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 1/2513 [00:28<19:46:45, 28.35s/it]







































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A







































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 1/2513 [00:37<26:07:58, 37.45s/it]






































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 1/2513 [00:31<22:10:44, 31.79s/it]





































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 1/2513 [00:37<26:19:04, 37.72s/it]




































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 2/2513 [00:37<13:13:10, 18.95s/it]



































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 2/2513 [00:37<13:06:50, 18.80s/it]


































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 2/2513 [00:36<12:53:50, 18.49s/it]

































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 2/2513 [00:38<13:28:12, 19.31s/it]
































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 2/2513 [00:36<12:45:11, 18.28s/it]































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









                                                   [A[A[A[A[A[A[A[A[A[A















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










[A[A[A[A[A[A[A[A[A[A[A












[A[A[A[A[A[A[A[A[A[A[A[A[A























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A































[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











[A[A[A[A[A[A[A[A[A[A[A[A













[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 2/2513 [01:32<32:14:18, 46.22s/it]
  0%|          | 1/2513 [00:27<19:30:46, 27.96s/it]






























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 0/2513 [00:28<?, ?it/s]





























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 2/2513 [00:41<14:32:30, 20.85s/it]




























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 1/2513 [00:32<22:43:23, 32.57s/it]



























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 2/2513 [00:40<14:00:36, 20.09s/it]


























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 3/2513 [00:46<10:42:39, 15.36s/it]

























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A


















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













[A[A[A[A[A[A[A[A[A[A[A[A[A[A











[A[A[A[A[A[A[A[A[A[A[A[A



















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












[A[A[A[A[A[A[A[A[A[A[A[A[A





















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 1/2513 [00:47<33:11:14, 47.56s/it]
























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A

















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













[A[A[A[A[A[A[A[A[A[A[A[A[A[A








[A[A[A[A[A[A[A[A[A












[A[A[A[A[A[A[A[A[A[A[A[A[A









[A[A[A[A[A[A[A[A[A[A







                                                  [A[A[A[A[A[A[A[A






                                                   [A[A[A[A[A[A[A










[A[A[A[A[A[A[A[A[A[A[A


















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A





















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A






















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











[A[A[A[A[A[A[A[A[A[A[A[A




                                                  [A[A[A[A[A





                                                   [A[A[A[A[A[A




















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 3/2513 [01:32<21:29:23, 30.82s/it]























[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 0/2513 [00:28<?, ?it/s]






















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A




















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A



















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 1/2513 [00:33<23:42:40, 33.98s/it]





















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 1/2513 [00:30<21:33:57, 30.91s/it]




















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












[A[A[A[A[A[A[A[A[A[A[A[A[A







[A[A[A[A[A[A[A[A











[A[A[A[A[A[A[A[A[A[A[A[A








[A[A[A[A[A[A[A[A[A






[A[A[A[A[A[A[A
                                                   [A

                                                   [A[A


                                                   [A[A[A





[A[A[A[A[A[A









[A[A[A[A[A[A[A[A[A[A

















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A










[A[A[A[A[A[A[A[A[A[A[A



[A[A[A[A




[A[A[A[A[A


















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













[A[A[A[A[A[A[A[A[A[A[A[A[A[A















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 5/2513 [01:37<13:33:51, 19.47s/it]



















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













[A[A[A[A[A[A[A[A[A[A[A[A[A[A











[A[A[A[A[A[A[A[A[A[A[A[A






[A[A[A[A[A[A[A










[A[A[A[A[A[A[A[A[A[A[A







[A[A[A[A[A[A[A[A








[A[A[A[A[A[A[A[A[A
















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A









[A[A[A[A[A[A[A[A[A[A

















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












[A[A[A[A[A[A[A[A[A[A[A[A[A














[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 7/2513 [01:33<9:17:27, 13.35s/it]


















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A














[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 1/2513 [00:37<25:57:27, 37.20s/it]

















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A













[A[A[A[A[A[A[A[A[A[A[A[A[A[A












[A[A[A[A[A[A[A[A[A[A[A[A[A














[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 2/2513 [00:39<13:51:38, 19.87s/it]
















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A












[A[A[A[A[A[A[A[A[A[A[A[A[A











[A[A[A[A[A[A[A[A[A[A[A[A










[A[A[A[A[A[A[A[A[A[A[A





[A[A[A[A[A[A









[A[A[A[A[A[A[A[A[A[A






[A[A[A[A[A[A[A




[A[A[A[A[A







[A[A[A[A[A[A[A[A













[A[A[A[A[A[A[A[A[A[A[A[A[A[A








[A[A[A[A[A[A[A[A[A














[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 2/2513 [01:34<33:01:14, 47.34s/it]















[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A











[A[A[A[A[A[A[A[A[A[A[A[A










[A[A[A[A[A[A[A[A[A[A[A









[A[A[A[A[A[A[A[A[A[A




[A[A[A[A[A








[A[A[A[A[A[A[A[A[A





[A[A[A[A[A[A



[A[A[A[A






[A[A[A[A[A[A[A












[A[A[A[A[A[A[A[A[A[A[A[A[A







[A[A[A[A[A[A[A[A













[A[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 7/2513 [01:34<9:24:56, 13.53s/it]














[A[A[A[A[A[A[A[A[A[A[A[A[A[A












[A[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 1/2513 [00:34<24:11:57, 34.68s/it]













[A[A[A[A[A[A[A[A[A[A[A[A[A










[A[A[A[A[A[A[A[A[A[A[A









[A[A[A[A[A[A[A[A[A[A








[A[A[A[A[A[A[A[A[A



[A[A[A[A







[A[A[A[A[A[A[A[A




[A[A[A[A[A





[A[A[A[A[A[A






[A[A[A[A[A[A[A











[A[A[A[A[A[A[A[A[A[A[A[A  0%|          | 3/2513 [01:34<21:59:03, 31.53s/it]












[A[A[A[A[A[A[A[A[A[A[A[A









[A[A[A[A[A[A[A[A[A[A








[A[A[A[A[A[A[A[A[A







[A[A[A[A[A[A[A[A










[A[A[A[A[A[A[A[A[A[A[A  0%|          | 3/2513 [00:44<10:21:22, 14.85s/it]











[A[A[A[A[A[A[A[A[A[A[A








[A[A[A[A[A[A[A[A[A







[A[A[A[A[A[A[A[A






[A[A[A[A[A[A[A



[A[A[A[A




[A[A[A[A[A





[A[A[A[A[A[A









[A[A[A[A[A[A[A[A[A[A  0%|          | 1/2513 [00:48<33:53:40, 48.58s/it]










[A[A[A[A[A[A[A[A[A[A







[A[A[A[A[A[A[A[A






[A[A[A[A[A[A[A








[A[A[A[A[A[A[A[A[A  0%|          | 2/2513 [00:42<14:49:33, 21.26s/it]









[A[A[A[A[A[A[A[A[A






[A[A[A[A[A[A[A







[A[A[A[A[A[A[A[A  0%|          | 2/2513 [00:39<13:45:22, 19.72s/it]








[A[A[A[A[A[A[A[A






[A[A[A[A[A[A[A  0%|          | 1/2513 [00:35<24:33:21, 35.19s/it]
  0%|          | 1/2513 [00:28<19:37:34, 28.13s/it]



[A[A[A

[A[A



[A[A[A[A




[A[A[A[A[A





[A[A[A[A[A[A  0%|          | 5/2513 [01:36<13:27:07, 19.31s/it]


[A[A
[A


[A[A[A



[A[A[A[A




[A[A[A[A[A  0%|          | 5/2513 [01:37<13:32:05, 19.43s/it]



[A[A[A



[A[A[A[A  0%|          | 1/2513 [00:47<32:59:54, 47.29s/it]

[A

[A[A


[A[A[A  0%|          | 4/2513 [01:34<16:30:16, 23.68s/it]


[A[A  0%|          | 3/2513 [00:45<10:33:14, 15.14s/it]

[A  0%|          | 2/2513 [00:48<16:47:27, 24.07s/it]
  0%|          | 1/2513 [00:33<23:24:04, 33.54s/it]
